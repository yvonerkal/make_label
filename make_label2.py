import streamlit as st
from streamlit_drawable_canvas import st_canvas
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import soundfile as sf
import pandas as pd
import os
import io
import zipfile
from io import BytesIO
from PIL import Image
import uuid
from pypinyin import lazy_pinyin
import sys
from datetime import datetime

# ======== å­—ä½“è®¾ç½® =========
def setup_matplotlib_font():
    """é…ç½®Matplotlibä½¿ç”¨ç³»ç»Ÿå¯ç”¨å­—ä½“ï¼Œé¿å…å­—ä½“æŸ¥æ‰¾è­¦å‘Š"""
    system_fonts = fm.findSystemFonts()
    sans_serif_fonts = [f for f in system_fonts if 'sans' in f.lower() or 'arial' in f.lower()]
    
    if sans_serif_fonts:
        plt.rcParams["font.family"] = ["sans-serif"]
        plt.rcParams["font.sans-serif"] = [fm.FontProperties(fname=sans_serif_fonts[0]).get_name()]
    else:
        plt.rcParams["font.family"] = ["DejaVu Sans", "Arial", "Helvetica"]
    
    plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# åˆå§‹åŒ–æ—¶å°±è®¾ç½®å­—ä½“
setup_matplotlib_font()

# ======== ä¼šè¯ç®¡ç† =========
def init_session():
    """åˆå§‹åŒ–å¹¶ç¡®ä¿ä¼šè¯å”¯ä¸€æ€§"""
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    
    # æ¸…é™¤è¿‡æœŸçš„ä¼šè¯æ•°æ®
    if "last_activity" in st.session_state:
        idle_time = (datetime.now() - st.session_state.last_activity).total_seconds()
        if idle_time > 3600:  # 1å°æ—¶æ— æ´»åŠ¨åˆ™é‡ç½®ä¼šè¯
            reset_session()
    
    st.session_state.last_activity = datetime.now()

def reset_session():
    """é‡ç½®ä¼šè¯çŠ¶æ€"""
    for key in list(st.session_state.keys()):
        if key != "session_id":
            del st.session_state[key]
    st.info("ä¼šè¯å·²é‡ç½®ä»¥è§£å†³å¯èƒ½çš„å†²çª")

# ======== å·¥å…·å‡½æ•° =========
@st.cache_data(show_spinner=False)
def load_audio(file):
    """åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼Œå¢åŠ é”™è¯¯å¤„ç†"""
    try:
        return librosa.load(file, sr=None)
    except Exception as e:
        st.error(f"åŠ è½½éŸ³é¢‘å¤±è´¥: {str(e)}")
        return None, None

@st.cache_data(show_spinner=False)
def validate_audio_file(file):
    """éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ"""
    try:
        # å°è¯•è·å–éŸ³é¢‘æ—¶é•¿
        duration = librosa.get_duration(filename=file)
        return True, duration
    except Exception as e:
        st.error(f"éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")
        return False, 0

def generate_spectrogram_data(y, sr):
    """ç”Ÿæˆé¢‘è°±å›¾æ•°æ®åŠåæ ‡è½´èŒƒå›´ï¼ˆç”¨äºåæ ‡è½¬æ¢ï¼‰"""
    if y is None or sr is None:
        return None, None, None
        
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    times = librosa.times_like(D, sr=sr)
    frequencies = librosa.fft_frequencies(sr=sr)
    return D, times, frequencies

def generate_spectrogram_image(D, times, frequencies):
    """ç”Ÿæˆå¸¦åæ ‡çš„é¢‘è°±å›¾ï¼ˆç¡®ä¿x/yè½´èŒƒå›´æ˜ç¡®ï¼‰"""
    if D is None or times is None or frequencies is None:
        return None
        
    plt.figure(figsize=(12, 6), dpi=100)
    img = librosa.display.specshow(
        D,
        sr=frequencies[-1] * 2,
        x_axis='time',
        y_axis='log',
    )
    plt.xlim(times[0], times[-1])
    plt.ylim(frequencies[0], frequencies[-1])
    plt.colorbar(format='%+2.0f dB')
    plt.title('Spectrogram')
    plt.tight_layout(pad=0)

    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)
    buf.seek(0)
    img = Image.open(buf)
    plt.close()
    return img

@st.cache_data(show_spinner=False)
def generate_waveform_image(y, sr):
    if y is None or sr is None:
        return None
        
    plt.figure(figsize=(12, 3), dpi=100)
    librosa.display.waveshow(y, sr=sr)
    plt.title('Waveform')
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    plt.close()
    return Image.open(buf)

def get_pinyin_abbr(text):
    return ''.join([p[0] for p in lazy_pinyin(text) if p])

def get_full_pinyin(text):
    return ''.join(lazy_pinyin(text))

# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
init_session()  # åˆå§‹åŒ–ä¼šè¯

if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = []
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()
if "audio_state" not in st.session_state:
    st.session_state.audio_state = {
        "processed_files": set(),
        "current_index": 0,
        "segment_info": {},
        "last_audio_file": None,
        "last_seg_idx": -1,
    }
if "filtered_labels_cache" not in st.session_state:
    st.session_state.filtered_labels_cache = {}
if "canvas_boxes" not in st.session_state:
    st.session_state.canvas_boxes = []
if "spec_params" not in st.session_state:
    st.session_state.spec_params = {"times": None, "frequencies": None, "img_size": (0, 0)}
if "spec_image" not in st.session_state:
    st.session_state.spec_image = None

st.set_page_config(layout="wide")
st.title("é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")

# ======== æ ‡ç­¾ç®¡ç†ç»„ä»¶ =========
def label_management_component():
    with st.sidebar:
        st.markdown("### ğŸ·ï¸ æ ‡ç­¾è®¾ç½®")
        with st.form("label_form", clear_on_submit=True):
            label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", type=["txt"], key="label_file")
            submit_label = st.form_submit_button("åŠ è½½æ ‡ç­¾")
            if submit_label and label_file:
                try:
                    species_list = [line.strip() for line in label_file.read().decode("utf-8").split("\n") if
                                    line.strip()]
                    st.session_state["dynamic_species_list"] = species_list
                    st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(species_list)} ä¸ªæ ‡ç­¾")
                    st.rerun()
                except Exception as e:
                    st.error(f"é”™è¯¯ï¼š{str(e)}")
        st.markdown("#### å½“å‰æ ‡ç­¾é¢„è§ˆ")
        st.write(st.session_state["dynamic_species_list"][:5] + (
            ["..."] if len(st.session_state["dynamic_species_list"]) > 5 else []))

        # æ ‡æ³¨æ¨¡å¼é€‰æ‹©
        st.session_state.annotation_mode = st.radio(
            "æ ‡æ³¨æ¨¡å¼",
            ["åˆ†æ®µæ ‡æ³¨", "é¢‘è°±å›¾ç”»æ¡†"],
            index=0 if st.session_state.get("annotation_mode") == "åˆ†æ®µæ ‡æ³¨" else 1
        )
    return st.session_state["dynamic_species_list"]

# ======== é¢‘è°±å›¾ç”»æ¡†+æ ‡ç­¾å…³è”ç»„ä»¶ =========
def spectral_annotation_component(y, sr, current_segment_key):
    # ç”Ÿæˆé¢‘è°±å›¾æ•°æ®ï¼ˆæ—¶é—´ã€é¢‘ç‡èŒƒå›´ï¼‰
    D, times, frequencies = generate_spectrogram_data(y, sr)

    # ç¼“å­˜é¢‘è°±å›¾ï¼Œé¿å…é‡å¤ç”Ÿæˆ
    if st.session_state.spec_image is None:
        spec_image = generate_spectrogram_image(D, times, frequencies)
        st.session_state.spec_image = spec_image
    else:
        spec_image = st.session_state.spec_image

    if spec_image is None:
        st.error("æ— æ³•ç”Ÿæˆé¢‘è°±å›¾ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ•°æ®")
        return False, False

    st.session_state.spec_params = {
        "times": times,
        "frequencies": frequencies,
        "img_size": (spec_image.width, spec_image.height)
    }

    # ä¸»åŒºåŸŸå¸ƒå±€ï¼šå·¦ä¾§ä¸ºæ“ä½œåŒºï¼ˆå›ºå®šç»“æ„ï¼‰ï¼Œå³ä¾§ä¸ºæ ‡ç­¾åŒºï¼ˆå¯æ»šåŠ¨ï¼‰
    col_main, col_labels = st.columns([3, 1])

    with col_main:
        st.subheader("ğŸ§ é¢‘è°±å›¾ç”»æ¡†æ ‡æ³¨ï¼ˆç‚¹å‡»ç”»å¸ƒç»˜åˆ¶çŸ©å½¢ï¼‰")

        # 1. éŸ³é¢‘æ’­æ”¾ç§»åˆ°é¢‘è°±å›¾ä¸Šæ–¹
        st.markdown("#### éŸ³é¢‘æ’­æ”¾")
        if y is not None and sr is not None:
            audio_bytes = BytesIO()
            sf.write(audio_bytes, y, sr, format='WAV')
            st.audio(audio_bytes, format="audio/wav", start_time=0)
        else:
            st.warning("æ— æ³•æ’­æ”¾éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ•°æ®")

        # 2. é¢‘è°±å›¾ç”»å¸ƒåŒºåŸŸ
        st.markdown("#### é¢‘è°±å›¾ï¼ˆå¯ç»˜åˆ¶çŸ©å½¢æ¡†ï¼‰")
        canvas_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=2,
            stroke_color="#FF0000",
            background_image=spec_image,
            height=spec_image.height,
            width=spec_image.width,
            drawing_mode="rect",
            key=f"canvas_{current_segment_key}",
            update_streamlit=True,
            display_toolbar=True
        )

        # å¤„ç†ç”»å¸ƒä¸Šçš„ç”»æ¡†
        if canvas_result.json_data is not None:
            st.session_state.canvas_boxes = [
                {
                    "pixel": {
                        "left": obj["left"],
                        "top": obj["top"],
                        "width": obj["width"],
                        "height": obj["height"]
                    },
                    "label": None
                }
                for obj in canvas_result.json_data["objects"]
                if obj["type"] == "rect"
            ]

        # 3. åˆ·æ–°æŒ‰é’®å’Œæ“ä½œæŒ‰é’®ç»„ï¼ˆå›ºå®šåœ¨é¢‘è°±å›¾ä¸‹æ–¹ï¼‰
        st.markdown("#### æ“ä½œ")
        button_row = st.columns([1, 1, 2])
        with button_row[0]:
            save_clicked = st.button("ä¿å­˜ç”»æ¡†æ ‡æ³¨", key=f"save_boxes_{current_segment_key}")
        with button_row[1]:
            skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_box_{current_segment_key}")

    # å³ä¾§æ ‡ç­¾ç®¡ç†åŒºåŸŸï¼ˆå¯æ»šåŠ¨ï¼Œä¸å½±å“å·¦ä¾§æŒ‰é’®ä½ç½®ï¼‰
    with col_labels:
        st.markdown("### æ¡†æ ‡ç­¾ç®¡ç†")
        species_list = st.session_state["dynamic_species_list"]
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return save_clicked, skip_clicked

        # æ˜¾ç¤ºæ‰€æœ‰ç”»æ¡†å¹¶å…³è”æ ‡ç­¾
        if st.session_state.canvas_boxes:
            for i, box in enumerate(st.session_state.canvas_boxes):
                st.markdown(f"#### æ¡† {i + 1}")

                # è½¬æ¢åƒç´ åæ ‡ä¸ºå®é™…æ—¶é—´å’Œé¢‘ç‡
                time_freq = pixel_to_time_freq(box["pixel"])
                st.write(f"æ—¶é—´èŒƒå›´ï¼š{time_freq['start']:.2f} - {time_freq['end']:.2f} ç§’")
                st.write(f"é¢‘ç‡èŒƒå›´ï¼š{time_freq['min']:.0f} - {time_freq['max']:.0f} Hz")

                # ä¸ºå½“å‰æ¡†é€‰æ‹©æ ‡ç­¾
                search_query = st.text_input(
                    "æœç´¢æ ‡ç­¾", "", key=f"box_search_{i}",
                    placeholder="è¾“å…¥ä¸­æ–‡/æ‹¼éŸ³é¦–å­—æ¯"
                )
                # è¿‡æ»¤æ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡ã€æ‹¼éŸ³é¦–å­—æ¯ã€å…¨æ‹¼ï¼‰
                filtered = []
                if search_query:
                    q = search_query.lower()
                    for label in species_list:
                        if q in label.lower() or q in get_pinyin_abbr(label).lower() or q in get_full_pinyin(
                                label).lower():
                            filtered.append(label)
                else:
                    filtered = species_list

                # é€‰æ‹©æ ‡ç­¾å¹¶ä¿å­˜
                selected_label = st.selectbox(
                    f"é€‰æ‹©æ¡† {i + 1} çš„æ ‡ç­¾",
                    filtered,
                    index=filtered.index(box["label"]) if box["label"] in filtered else 0,
                    key=f"box_label_{i}"
                )
                # æ›´æ–°å½“å‰æ¡†çš„æ ‡ç­¾
                if selected_label != box["label"]:
                    st.session_state.canvas_boxes[i]["label"] = selected_label
                    st.session_state.canvas_boxes = st.session_state.canvas_boxes  # è§¦å‘çŠ¶æ€æ›´æ–°

    return save_clicked, skip_clicked

# ======== åƒç´ åæ ‡â†’æ—¶é—´/é¢‘ç‡è½¬æ¢å‡½æ•° =========
def pixel_to_time_freq(pixel_coords):
    """å°†ç”»å¸ƒä¸Šçš„åƒç´ åæ ‡è½¬æ¢ä¸ºå®é™…çš„æ—¶é—´ï¼ˆç§’ï¼‰å’Œé¢‘ç‡ï¼ˆHzï¼‰"""
    times = st.session_state.spec_params["times"]
    frequencies = st.session_state.spec_params["frequencies"]
    img_width, img_height = st.session_state.spec_params["img_size"]

    if times is None or frequencies is None:
        return {"start": 0, "end": 0, "min": 0, "max": 0}

    # æ—¶é—´èŒƒå›´ï¼ˆxè½´ï¼‰ï¼šç”»å¸ƒå·¦â†’å³ = 0â†’5ç§’
    total_time = times[-1] - times[0]
    time_per_pixel = total_time / img_width
    start_time = times[0] + pixel_coords["left"] * time_per_pixel
    end_time = start_time + pixel_coords["width"] * time_per_pixel

    # é¢‘ç‡èŒƒå›´ï¼ˆyè½´ï¼‰ï¼šç”»å¸ƒä¸Šâ†’ä¸‹ = é«˜é¢‘â†’ä½é¢‘
    total_freq = frequencies[-1] - frequencies[0]
    freq_per_pixel = total_freq / img_height
    max_freq = frequencies[-1] - pixel_coords["top"] * freq_per_pixel
    min_freq = max_freq - pixel_coords["height"] * freq_per_pixel

    return {
        "start": round(max(0, start_time), 3),
        "end": round(min(5, end_time), 3),
        "min": round(max(0, min_freq), 1),
        "max": round(min(frequencies[-1], max_freq), 1)
    }

# ======== éŸ³é¢‘å¤„ç†ä¸»é€»è¾‘ =========
def process_audio():
    audio_state = st.session_state.audio_state
    output_dir = "annotated_audios"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")

    # åˆå§‹åŒ–CSV
    try:
        if not os.path.exists(csv_path):
            pd.DataFrame(columns=[
                "filename", "segment_index", "box_id",
                "start_time", "end_time", "min_freq", "max_freq", "label"
            ]).to_csv(csv_path, index=False, encoding='utf_8_sig')
        try:
            df_old = pd.read_csv(csv_path, encoding='utf_8_sig')
        except Exception as e:
            st.error(f"CSVæ–‡ä»¶é”™è¯¯ï¼š{str(e)}")
            return
    except Exception as e:
        st.error(f"CSVæ–‡ä»¶é”™è¯¯ï¼š{str(e)}")
        return

    with st.sidebar:
        st.markdown("### ğŸµ éŸ³é¢‘ä¸Šä¼ ")
        uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True, key="audio_files")
        st.markdown("### ğŸ“¥ ä¸‹è½½ç»“æœ")
        if os.path.exists(csv_path):
            with open(csv_path, "rb") as f:
                st.download_button("ğŸ“„ ä¸‹è½½æ ‡æ³¨ç»“æœ", f, "annotations.csv", "text/csv; charset=utf-8")
        if os.path.exists(output_dir):
            with zipfile.ZipFile(zip_buf := BytesIO(), "w") as zf:
                for f in os.listdir(output_dir):
                    if f.endswith(".wav"):
                        file_path = os.path.join(output_dir, f)
                        if os.path.exists(file_path):  # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
                            zf.write(file_path, f)
            zip_buf.seek(0)
            st.download_button("ğŸµ ä¸‹è½½éŸ³é¢‘ç‰‡æ®µ", zip_buf, "annotated_segments.zip", "application/zip")

    if not uploaded_files:
        st.info("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return

    # è·å–æœªå¤„ç†çš„éŸ³é¢‘
    unprocessed = [f for f in uploaded_files if f.name not in audio_state["processed_files"]]

    if unprocessed:
        audio_file = unprocessed[0]
        
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
        temp_audio_path = f"temp_{uuid.uuid4().hex}.wav"
        with open(temp_audio_path, "wb") as f:
            f.write(audio_file.getbuffer())
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        valid, duration = validate_audio_file(temp_audio_path)
        if not valid:
            st.error(f"éŸ³é¢‘æ–‡ä»¶ {audio_file.name} æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
            os.remove(temp_audio_path)
            return

        y, sr = load_audio(temp_audio_path)
        if y is None or sr is None:
            os.remove(temp_audio_path)
            return

        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / 5.0))

        # åˆå§‹åŒ–å½“å‰éŸ³é¢‘çš„åˆ†æ®µä¿¡æ¯
        if audio_file.name not in audio_state["segment_info"]:
            audio_state["segment_info"][audio_file.name] = {"current_seg": 0, "total_seg": total_segments}
        seg_idx = audio_state["segment_info"][audio_file.name]["current_seg"]
        current_segment_key = f"{audio_file.name}_{seg_idx}"

        # åˆ‡æ¢éŸ³é¢‘/åˆ†æ®µæ—¶é‡ç½®çŠ¶æ€
        if (audio_state["last_audio_file"] != audio_file.name or
                audio_state["last_seg_idx"] != seg_idx):
            st.session_state.current_selected_labels = set()
            st.session_state.canvas_boxes = []
            st.session_state.spec_image = None
            audio_state["last_audio_file"] = audio_file.name
            audio_state["last_seg_idx"] = seg_idx

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")
        start_sec, end_sec = seg_idx * 5.0, min((seg_idx + 1) * 5.0, total_duration)
        segment_y = y[int(start_sec * sr):int(end_sec * sr)]  # å½“å‰5ç§’ç‰‡æ®µ

        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ ‡æ³¨æ–¹å¼
        if st.session_state.annotation_mode == "é¢‘è°±å›¾ç”»æ¡†":
            save_clicked, skip_clicked = spectral_annotation_component(segment_y, sr, current_segment_key)

            # ä¿å­˜ç”»æ¡†æ ‡æ³¨
            if save_clicked:
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¡†éƒ½æœ‰æ ‡ç­¾
                if not st.session_state.canvas_boxes:
                    st.warning("è¯·å…ˆç»˜åˆ¶è‡³å°‘ä¸€ä¸ªæ¡†")
                    return
                if any(box["label"] is None for box in st.session_state.canvas_boxes):
                    st.warning("è¯·ä¸ºæ‰€æœ‰æ¡†æ·»åŠ æ ‡ç­¾")
                    return

                # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                base_name = os.path.splitext(audio_file.name)[0]
                unique_id = uuid.uuid4().hex[:8]
                segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜æ¯ä¸ªæ¡†çš„ä¿¡æ¯åˆ°CSV
                entries = []
                for box_id, box in enumerate(st.session_state.canvas_boxes):
                    time_freq = pixel_to_time_freq(box["pixel"])
                    entries.append({
                        "filename": audio_file.name,
                        "segment_index": segment_filename,
                        "box_id": box_id,
                        "start_time": time_freq["start"],
                        "end_time": time_freq["end"],
                        "min_freq": time_freq["min"],
                        "max_freq": time_freq["max"],
                        "label": box["label"]
                    })
                pd.DataFrame(entries).to_csv(csv_path, mode='a', header=False, index=False, encoding='utf_8_sig')

                # æ›´æ–°çŠ¶æ€ï¼Œè¿›å…¥ä¸‹ä¸€æ®µ
                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                    audio_state["processed_files"].add(audio_file.name)
                st.session_state.spec_image = None
                st.success(f"æˆåŠŸä¿å­˜ {len(entries)} ä¸ªæ¡†æ ‡æ³¨ï¼")
                st.balloons()
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)
                st.rerun()

            # è·³è¿‡å½“å‰æ®µ
            if skip_clicked:
                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                    audio_state["processed_files"].add(audio_file.name)
                st.session_state.spec_image = None
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)
                st.rerun()

        else:
            # åŸæœ‰åˆ†æ®µæ ‡æ³¨é€»è¾‘
            col_main, col_labels = st.columns([3, 1])
            with col_main:
                st.subheader("ğŸ§ æ’­æ”¾å½“å‰ç‰‡æ®µ")
                if segment_y is not None and sr is not None:
                    audio_bytes = BytesIO()
                    sf.write(audio_bytes, segment_y, sr, format='WAV')
                    st.audio(audio_bytes, format="audio/wav")
                else:
                    st.warning("æ— æ³•æ’­æ”¾éŸ³é¢‘ç‰‡æ®µï¼Œè¯·æ£€æŸ¥æ•°æ®")
                
                col1, col2 = st.columns(2)
                with col1:
                    waveform_img = generate_waveform_image(segment_y, sr)
                    if waveform_img is not None:
                        st.image(waveform_img, caption="Waveform", use_column_width=True)
                    else:
                        st.warning("æ— æ³•ç”Ÿæˆæ³¢å½¢å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
                with col2:
                    spec_data = generate_spectrogram_data(segment_y, sr)
                    spec_img = generate_spectrogram_image(*spec_data)
                    if spec_img is not None:
                        st.image(spec_img, caption="Spectrogram", use_column_width=True)
                    else:
                        st.warning("æ— æ³•ç”Ÿæˆé¢‘è°±å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")

            with col_labels:
                col_save, col_skip = annotation_labels_component(current_segment_key)
                if col_save and st.button("ä¿å­˜åˆ†æ®µæ ‡æ³¨", key=f"save_seg_{current_segment_key}"):
                    save_segment_annotation(audio_file, seg_idx, start_sec, end_sec, segment_y, sr, output_dir, temp_audio_path)
                if col_skip and st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_seg_{current_segment_key}"):
                    audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                    if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                        audio_state["processed_files"].add(audio_file.name)
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_audio_path):
                        os.remove(temp_audio_path)
                    st.rerun()

    else:
        st.success("ğŸ‰ æ‰€æœ‰éŸ³é¢‘æ ‡æ³¨å®Œæˆï¼")

    st.session_state.audio_state = audio_state
    # ç¡®ä¿åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if 'temp_audio_path' in locals() and os.path.exists(temp_audio_path):
        os.remove(temp_audio_path)

# ======== åˆ†æ®µæ ‡æ³¨ä¿å­˜å‡½æ•° =========
def save_segment_annotation(audio_file, seg_idx, start_sec, end_sec, segment_y, sr, output_dir, temp_audio_path=None):
    csv_path = os.path.join(output_dir, "annotations.csv")
    if not st.session_state.current_selected_labels:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾")
        return

    base_name = os.path.splitext(audio_file.name)[0]
    unique_id = uuid.uuid4().hex[:8]
    segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
    segment_path = os.path.join(output_dir, segment_filename)
    sf.write(segment_path, segment_y, sr)

    entry = {
        "filename": audio_file.name,
        "segment_index": segment_filename,
        "box_id": None,
        "start_time": round(start_sec, 3),
        "end_time": round(end_sec, 3),
        "min_freq": None,
        "max_freq": None,
        "label": ",".join(st.session_state.current_selected_labels)
    }
    pd.DataFrame([entry]).to_csv(csv_path, mode='a', header=False, index=False, encoding='utf_8_sig')

    audio_state = st.session_state.audio_state
    audio_state["segment_info"][audio_file.name]["current_seg"] += 1
    if audio_state["segment_info"][audio_file.name]["current_seg"] >= audio_state["segment_info"][audio_file.name][
        "total_seg"]:
        audio_state["processed_files"].add(audio_file.name)
    st.success(f"æˆåŠŸä¿å­˜åˆ†æ®µæ ‡æ³¨ï¼")
    st.balloons()
    
    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if temp_audio_path and os.path.exists(temp_audio_path):
        os.remove(temp_audio_path)
        
    st.rerun()

# ======== åŸæœ‰åˆ†æ®µæ ‡æ³¨æ ‡ç­¾ç»„ä»¶ =========
def annotation_labels_component(current_segment_key):
    species_list = st.session_state["dynamic_species_list"]
    col_labels = st.container()

    with col_labels:
        st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return None, None

        search_query = st.text_input("ğŸ” æœç´¢æ ‡ç­¾", "", key=f"search_{current_segment_key}")
        cache_key = f"{current_segment_key}_{search_query}"

        if cache_key not in st.session_state.filtered_labels_cache:
            filtered_species = []
            if search_query:
                search_lower = search_query.lower()
                for label in species_list:
                    if (search_lower in label.lower() or
                            search_lower in get_pinyin_abbr(label) or
                            search_lower in get_full_pinyin(label)):
                        filtered_species.append(label)
            else:
                filtered_species = species_list.copy()
            st.session_state.filtered_labels_cache[cache_key] = filtered_species

        filtered_species = st.session_state.filtered_labels_cache[cache_key]
        for label in filtered_species:
            key = f"label_{label}_{current_segment_key}"
            is_selected = label in st.session_state.current_selected_labels
            if st.checkbox(label, key=key, value=is_selected):
                st.session_state.current_selected_labels.add(label)
            else:
                st.session_state.current_selected_labels.discard(label)

        st.markdown("### å·²é€‰æ ‡ç­¾")
        st.info(f"å·²é€‰æ•°é‡ï¼š{len(st.session_state.current_selected_labels)}")
        col_save, col_skip = st.columns(2)
        return col_save, col_skip

if __name__ == "__main__":
    label_management_component()
    process_audio()
