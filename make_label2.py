import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import uuid
from PIL import Image
import zipfile
from io import BytesIO


# ======== å·¥å…·å‡½æ•° =========
@st.cache_data
def load_audio(file):
    return librosa.load(file, sr=None)


@st.cache_data
def generate_spectrogram_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


@st.cache_data
def generate_waveform_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


def is_fully_annotated(file):
    info = st.session_state.segment_info.get(file.name)
    if info is None:
        return False
    return info["current_seg"] >= info["total_seg"]


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "segment_info" not in st.session_state:
    st.session_state.segment_info = {}
if "last_audio_file" not in st.session_state:
    st.session_state.last_audio_file = None
if "last_seg_idx" not in st.session_state:
    st.session_state.last_seg_idx = -1
# æ–°å¢ï¼šæ ‡ç­¾ç›¸å…³çŠ¶æ€ï¼ˆä»ä¼˜åŒ–ç‰ˆæœ¬æ•´åˆï¼‰
if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = [
        "åŒ—æ–¹ç‹­å£è›™", "é»‘æ–‘ä¾§è¤¶è›™", "é‡‘çº¿è›™", "ç‰›è›™", "é¥°çº¹å§¬è›™", "ä¸­åèŸ¾èœ", "æ³½è›™", "å…¶ä»–"  # é»˜è®¤æ ‡ç­¾ï¼Œå¯è¢«ä¸Šä¼ æ–‡ä»¶è¦†ç›–
    ]
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()


st.set_page_config(layout="wide")
st.title("é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")


# ======== æ ‡ç­¾ç®¡ç†ç»„ä»¶ï¼ˆä»ä¼˜åŒ–ç‰ˆæœ¬æ•´åˆï¼Œç¡®ä¿ä¸å½±å“ä¿å­˜åŠŸèƒ½ï¼‰ =========
def label_management_component():
    """ä¾§è¾¹æ æ ‡ç­¾ä¸Šä¼ ç»„ä»¶ï¼ŒåŠ¨æ€æ›´æ–°æ ‡ç­¾åˆ—è¡¨"""
    with st.sidebar:
        st.markdown("### ğŸ·ï¸ æ ‡ç­¾è®¾ç½®")
        # ä½¿ç”¨è¡¨å•é¿å…é¢‘ç¹é‡è¿è¡Œï¼Œç¡®ä¿ä¿å­˜åŠŸèƒ½ç¨³å®š
        with st.form("label_form", clear_on_submit=True):
            label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", type=["txt"], key="label_file")
            submit_label = st.form_submit_button("åŠ è½½æ ‡ç­¾")
            
            if submit_label and label_file:
                try:
                    # è¯»å–å¹¶è§£ç æ ‡ç­¾æ–‡ä»¶
                    content = label_file.read().decode("utf-8")
                    species_list = [line.strip() for line in content.split("\n") if line.strip()]
                    if species_list:
                        st.session_state["dynamic_species_list"] = species_list
                        st.success(f"æˆåŠŸåŠ è½½ {len(species_list)} ä¸ªæ ‡ç­¾ï¼")
                        st.rerun()  # åˆ·æ–°é¡µé¢ä½¿æ ‡ç­¾ç”Ÿæ•ˆ
                    else:
                        st.error("æ ‡ç­¾æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å†…å®¹")
                except UnicodeDecodeError:
                    st.error("æ ‡ç­¾æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨UTF-8ç¼–ç ")
                except Exception as e:
                    st.error(f"æ ‡ç­¾æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")


# ======== ä¾§è¾¹æ ï¼ˆæ•´åˆä¿å­˜ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬ï¼‰ =========
with st.sidebar:
    # å…ˆåŠ è½½æ ‡ç­¾ç®¡ç†ç»„ä»¶ï¼ˆæ–°å¢ï¼‰
    label_management_component()
    
    # ä¿ç•™åŸç‰ˆæœ¬çš„éŸ³é¢‘ä¸Šä¼ å’Œè¾“å‡ºè®¾ç½®ï¼ˆç¡®ä¿ä¿å­˜åŠŸèƒ½ç¨³å®šï¼‰
    uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True)
    output_dir = "E:/Frog audio classification/uploaded_audios"  # ä¿ç•™åŸè·¯å¾„ï¼Œç¡®ä¿ä¿å­˜é€»è¾‘ä¸å˜
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")
    if os.path.exists(csv_path):
        df_old = pd.read_csv(csv_path, encoding="utf-8")
    else:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])

    # ä¸‹è½½åŒºåŸŸï¼ˆä¿ç•™åŸç‰ˆæœ¬ï¼Œç¡®ä¿ç¨³å®šï¼‰
    st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡æ³¨ç»“æœ")
    if os.path.exists(csv_path):
        with open(csv_path, "rb") as f:
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ ‡æ³¨CSVæ–‡ä»¶",
                data=f,
                file_name="annotations.csv",
                mime="text/csv"
            )

    # éŸ³é¢‘ç‰‡æ®µä¸‹è½½ï¼ˆä¿ç•™åŸç‰ˆæœ¬çš„ç¨³å®šé€»è¾‘ï¼‰
    annotated_paths = []
    if os.path.exists(csv_path):
        df_tmp = pd.read_csv(csv_path)
        if "segment_index" in df_tmp.columns:
            for idx, row in df_tmp.iterrows():
                try:
                    fname = str(row["segment_index"])
                    if pd.notna(fname) and fname.strip() != "":
                        full_path = os.path.join(output_dir, fname)
                        if os.path.exists(full_path):
                            annotated_paths.append(full_path)
                except Exception as e:
                    st.warning(f"å¤„ç†éŸ³é¢‘ç‰‡æ®µè·¯å¾„æ—¶å‡ºé”™: {str(e)}")
        else:
            st.warning("CSVæ–‡ä»¶ä¸­ç¼ºå°‘ 'segment_index' åˆ—ï¼Œæ— æ³•ç”ŸæˆéŸ³é¢‘ä¸‹è½½åŒ…")

    if annotated_paths:
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zip_file:
            for path in annotated_paths:
                zip_file.write(path, os.path.basename(path))
        zip_buffer.seek(0)
        st.download_button(
            label="ğŸµ ä¸‹è½½æ ‡æ³¨éŸ³é¢‘ (ZIP)",
            data=zip_buffer,
            file_name="annotated_audio_segments.zip",
            mime="application/zip"
        )

    # æ ‡æ³¨çŠ¶æ€æ˜¾ç¤ºï¼ˆä¿ç•™åŸç‰ˆæœ¬ï¼‰
    if uploaded_files:
        with st.expander("âœ… å·²æ ‡æ³¨éŸ³é¢‘", expanded=True):
            for f in uploaded_files:
                if f.name in st.session_state.processed_files:
                    st.write(f.name)
        with st.expander("ğŸ•“ æœªæ ‡æ³¨éŸ³é¢‘", expanded=True):
            st.write([f.name for f in uploaded_files if f.name not in st.session_state.processed_files])


# ======== ä¸»å¤„ç†åŒºåŸŸï¼ˆä»¥åŸç‰ˆæœ¬ä¸ºåŸºç¡€ï¼Œæ•´åˆæ ‡ç­¾åŠŸèƒ½ï¼‰ =========
SEGMENT_DURATION = 5.0  # æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰


if uploaded_files:
    unprocessed = [f for f in uploaded_files if not is_fully_annotated(f)]

    if st.session_state.current_index < len(unprocessed):
        audio_file = unprocessed[st.session_state.current_index]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / SEGMENT_DURATION))

        if audio_file.name not in st.session_state.segment_info:
            st.session_state.segment_info[audio_file.name] = {"current_seg": 0, "total_seg": total_segments}
        seg_info = st.session_state.segment_info[audio_file.name]
        seg_idx = seg_info["current_seg"]

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")

        # è®¡ç®—å½“å‰ç‰‡æ®µçš„æ—¶é—´èŒƒå›´ï¼ˆä¿ç•™åŸç‰ˆæœ¬é€»è¾‘ï¼Œç¡®ä¿ä¿å­˜æ­£ç¡®ï¼‰
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]

        # å¸ƒå±€ï¼šå·¦ä¾§éŸ³é¢‘ä¿¡æ¯ï¼Œå³ä¾§æ ‡ç­¾ï¼ˆæ•´åˆä¼˜åŒ–ç‰ˆæœ¬çš„å¸ƒå±€ï¼‰
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            # æ’­æ”¾éŸ³é¢‘æ®µï¼ˆä¿ç•™åŸç‰ˆæœ¬ç¨³å®šé€»è¾‘ï¼‰
            st.subheader("ğŸ§ æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ")
            audio_bytes = io.BytesIO()
            sf.write(audio_bytes, segment_y, sr, format='WAV')
            st.audio(audio_bytes, format="audio/wav", start_time=0)

            # æ³¢å½¢å›¾ + é¢‘è°±å›¾ï¼ˆä¿ç•™åŸç‰ˆæœ¬ï¼‰
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
                wave_img = generate_waveform_image(segment_y, sr)
                st.image(wave_img, caption="Waveform", use_container_width=True)
            with col2:
                st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
                spec_img = generate_spectrogram_image(segment_y, sr)
                st.image(spec_img, caption="Spectrogram (dB)", use_container_width=True)

        with col_labels:  # å³ä¾§æ ‡ç­¾åŒºåŸŸï¼Œä½¿ç”¨åŠ¨æ€æ ‡ç­¾åˆ—è¡¨
            st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
            species_list = st.session_state["dynamic_species_list"]  # ä»sessionè·å–åŠ¨æ€æ ‡ç­¾
            current_key_prefix = f"{audio_file.name}_{seg_idx}"

            # åˆ‡æ¢ç‰‡æ®µæ—¶é‡ç½®å¤é€‰æ¡†çŠ¶æ€ï¼ˆæ•´åˆä¼˜åŒ–ç‰ˆæœ¬çš„çŠ¶æ€ç®¡ç†ï¼‰
            if (st.session_state.last_audio_file != audio_file.name
                    or st.session_state.last_seg_idx != seg_idx):
                st.session_state.current_selected_labels = set()  # é‡ç½®å·²é€‰æ ‡ç­¾
                st.session_state.last_audio_file = audio_file.name
                st.session_state.last_seg_idx = seg_idx

            # æ¸²æŸ“å¤é€‰æ¡†å¹¶æ”¶é›†é€‰ä¸­çš„æ ‡ç­¾ï¼ˆä½¿ç”¨åŠ¨æ€æ ‡ç­¾åˆ—è¡¨ï¼‰
            selected_labels = []
            for label in species_list:
                key = f"label_checkbox_{label}_{current_key_prefix}"
                if key not in st.session_state:
                    st.session_state[key] = False
                checked = st.checkbox(label, key=key, value=st.session_state[key])
                if checked != st.session_state[key]:
                    st.session_state[key] = checked
                if st.session_state[key]:
                    selected_labels.append(label)

            # æ˜¾ç¤ºå·²é€‰æ ‡ç­¾ï¼ˆä¼˜åŒ–æ˜¾ç¤ºä½ç½®ï¼Œä¿ç•™åŸç‰ˆæœ¬çš„æç¤ºé€»è¾‘ï¼‰
            if selected_labels:
                st.success(f"å·²é€‰æ ‡ç­¾: {', '.join(selected_labels)}")
            else:
                st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾")

            # æ“ä½œæŒ‰é’®ï¼ˆä¿ç•™åŸç‰ˆæœ¬çš„ç¨³å®šé€»è¾‘ï¼‰
            col_save, col_skip = st.columns(2)
            with col_save:
                save_clicked = st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_btn_{current_key_prefix}")
            with col_skip:
                skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_btn_{current_key_prefix}")

        # ä¿å­˜é€»è¾‘ï¼ˆå®Œå…¨ä¿ç•™åŸç‰ˆæœ¬ï¼Œç¡®ä¿ç¨³å®šï¼‰
        if save_clicked:
            if not selected_labels:
                st.warning("â—è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰©ç§æ ‡ç­¾ï¼")
            else:
                # ä¿å­˜åˆ†ç‰‡éŸ³é¢‘ï¼ˆåŸç‰ˆæœ¬éªŒè¯æœ‰æ•ˆçš„é€»è¾‘ï¼‰
                segment_filename = f"{os.path.splitext(audio_file.name)[0]}_seg{seg_idx}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜åˆ°CSVï¼ˆåŸç‰ˆæœ¬éªŒè¯æœ‰æ•ˆçš„é€»è¾‘ï¼‰
                entry = {
                    "filename": audio_file.name,
                    "segment_index": segment_filename,
                    "start_time": round(start_sec, 3),
                    "end_time": round(end_sec, 3),
                    "labels": ",".join(selected_labels)
                }

                st.session_state.annotations.append(entry)
                df_combined = pd.concat([df_old, pd.DataFrame([entry])], ignore_index=True)
                df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")

                # åˆ‡æ¢åˆ†ç‰‡æˆ–ä¸‹ä¸€ä¸ªæ–‡ä»¶ï¼ˆåŸç‰ˆæœ¬é€»è¾‘ï¼‰
                if seg_idx + 1 < total_segments:
                    st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                else:
                    st.session_state.processed_files.add(audio_file.name)
                    st.session_state.current_index += 1

                st.success("æ ‡æ³¨å·²ä¿å­˜ï¼")
                st.rerun()

        if skip_clicked:  # ä¿ç•™åŸç‰ˆæœ¬çš„è·³è¿‡é€»è¾‘
            if seg_idx + 1 < total_segments:
                st.session_state.segment_info[audio_file.name]["current_seg"] += 1
            else:
                st.session_state.processed_files.add(audio_file.name)
                st.session_state.current_index += 1
            st.rerun()

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆï¼ˆä¿ç•™åŸç‰ˆæœ¬é€»è¾‘ï¼‰
    all_done = True
    for f in uploaded_files:
        info = st.session_state.segment_info.get(f.name)
        if info is None or info["current_seg"] < info["total_seg"]:
            all_done = False
            break
    if all_done:
        st.success("ğŸ‰ æ‰€æœ‰ä¸Šä¼ çš„éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆï¼")

else:
    st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è‡³å°‘ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")
