import streamlit as st
from streamlit_drawable_canvas import st_canvas
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import uuid
from PIL import Image
import zipfile
from io import BytesIO


# ======== å·¥å…·å‡½æ•°ï¼ˆä¼˜åŒ–ï¼šæ·»åŠ ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—ï¼‰=========
@st.cache_data
def load_audio(file):
    return librosa.load(file, sr=None)

@st.cache_data  # ç¼“å­˜é¢‘è°±å›¾ç”Ÿæˆç»“æœ
def generate_spectrogram_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)

@st.cache_data  # æ–°å¢ï¼šç¼“å­˜æ³¢å½¢å›¾ç”Ÿæˆç»“æœ
def generate_waveform_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


def is_fully_annotated(file):
    info = st.session_state.segment_info.get(file.name)
    if info is None:
        return False
    return info["current_seg"] >= info["total_seg"]


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "label_reset_key" not in st.session_state:
    st.session_state.label_reset_key = str(uuid.uuid4())
if "selected_labels" not in st.session_state:
    st.session_state.selected_labels = set()
if "reset_checkboxes" not in st.session_state:
    st.session_state.reset_checkboxes = False
if "segment_info" not in st.session_state:
    st.session_state.segment_info = {}
if "last_audio_file" not in st.session_state:
    st.session_state.last_audio_file = None
if "last_seg_idx" not in st.session_state:
    st.session_state.last_seg_idx = -1


st.set_page_config(layout="wide")

st.title("ğŸ¸ é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")

# ======== ä¾§è¾¹æ ï¼ˆä¼˜åŒ–ï¼šå‡å°‘é‡å¤æ¸²æŸ“åŒºåŸŸï¼‰=========
with st.sidebar:
    uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True)
    output_dir = st.text_input("ä¿å­˜ç›®å½•", "E:/Frog audio classification/uploaded_audios")
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")
    if os.path.exists(csv_path):
        df_old = pd.read_csv(csv_path, encoding="utf-8")
    else:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])
    
    # ä¸‹è½½åŒºåŸŸ
    st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡æ³¨ç»“æœ")
    if os.path.exists(csv_path):
        with open(csv_path, "rb") as f:
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ ‡æ³¨CSVæ–‡ä»¶",
                data=f,
                file_name="annotations.csv",
                mime="text/csv"
            )
    
    # éŸ³é¢‘ç‰‡æ®µä¸‹è½½ï¼ˆä¼˜åŒ–ï¼šä»…åœ¨æœ‰æ ‡æ³¨æ—¶è®¡ç®—ï¼‰
    annotated_paths = []
    if os.path.exists(csv_path):
        df_tmp = pd.read_csv(csv_path)
        for fname in df_tmp["segment_index"]:
            full_path = os.path.join(output_dir, fname)
            if os.path.exists(full_path):
                annotated_paths.append(full_path)
    
    if annotated_paths:
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zip_file:
            for path in annotated_paths:
                arcname = os.path.basename(path)
                zip_file.write(path, arcname=arcname)
        zip_buffer.seek(0)
        st.download_button(
            label="ğŸµ ä¸‹è½½æ ‡æ³¨éŸ³é¢‘ (ZIP)",
            data=zip_buffer,
            file_name="annotated_audio_segments.zip",
            mime="application/zip"
        )
    
    # æ ‡æ³¨çŠ¶æ€æ˜¾ç¤ºï¼ˆä¼˜åŒ–ï¼šä»…åœ¨æœ‰æ–‡ä»¶æ—¶æ˜¾ç¤ºï¼‰
    if uploaded_files:
        with st.expander("âœ… å·²æ ‡æ³¨éŸ³é¢‘", expanded=True):
            for f in uploaded_files:
                if f.name in st.session_state.processed_files:
                    st.write(f.name)
        with st.expander("ğŸ•“ æœªæ ‡æ³¨éŸ³é¢‘", expanded=True):
            st.write([f.name for f in uploaded_files if f.name not in st.session_state.processed_files])


# ======== ä¸»å¤„ç†åŒºåŸŸï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šå‡å°‘æ ‡ç­¾é€‰æ‹©æ—¶çš„æ¸²æŸ“èŒƒå›´ï¼‰=========
SEGMENT_DURATION = 5.0  # æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰

if uploaded_files:
    unprocessed = [f for f in uploaded_files if not is_fully_annotated(f)]

    if st.session_state.current_index < len(unprocessed):
        audio_file = unprocessed[st.session_state.current_index]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / SEGMENT_DURATION))

        if audio_file.name not in st.session_state.segment_info:
            st.session_state.segment_info[audio_file.name] = {"current_seg": 0, "total_seg": total_segments}

        seg_info = st.session_state.segment_info[audio_file.name]
        seg_idx = seg_info["current_seg"]

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")

        # åˆ‡æ¢ç‰‡æ®µæ—¶æ¸…ç©ºæ ‡ç­¾ï¼ˆä¼˜åŒ–ï¼šä»…åœ¨çœŸæ­£åˆ‡æ¢æ—¶æ‰§è¡Œï¼‰
        if st.session_state.last_audio_file != audio_file.name or st.session_state.last_seg_idx != seg_idx:
            st.session_state.selected_labels.clear()
            st.session_state.last_audio_file = audio_file.name
            st.session_state.last_seg_idx = seg_idx

        # è®¡ç®—å½“å‰æ®µè½çš„æ—¶é—´èŒƒå›´
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]

        # æ’­æ”¾éŸ³é¢‘æ®µï¼ˆä¼˜åŒ–ï¼šä»…éŸ³é¢‘ç‰‡æ®µå˜åŒ–æ—¶é‡æ–°ç”Ÿæˆï¼‰
        st.subheader("ğŸ§ æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ")
        audio_bytes = io.BytesIO()
        sf.write(audio_bytes, segment_y, sr, format='WAV')
        st.audio(audio_bytes, format="audio/wav", start_time=0)

        # æ³¢å½¢å›¾ + é¢‘è°±å›¾ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜ç»“æœï¼Œå‡å°‘é‡å¤ç»˜åˆ¶ï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
            wave_img = generate_waveform_image(segment_y, sr)
            st.image(wave_img, caption="Waveform", use_container_width=True)

        with col2:
            st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
            spec_img = generate_spectrogram_image(segment_y, sr)
            st.image(spec_img, caption="Spectrogram (dB)", use_container_width=True)

        # æ ‡ç­¾é€‰æ‹©åŒºåŸŸï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šç”¨multiselectæ›¿ä»£checkboxï¼Œå‡å°‘äº¤äº’æ¬¡æ•°ï¼‰
        st.markdown("### ğŸ¸ è¯·é€‰æ‹©è¯¥æ®µéŸ³é¢‘ä¸­å‡ºç°çš„ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
        species_list = ["Rana", "Hyla", "Bufo", "Fejervarya", "Microhyla", "Other"]
        # ä½¿ç”¨multiselectå®ç°é«˜æ•ˆå¤šé€‰ï¼Œä»…åœ¨é€‰æ‹©å˜åŒ–æ—¶è§¦å‘æ¸²æŸ“
        selected_labels = st.multiselect(
            "ç‰©ç§æ ‡ç­¾",
            species_list,
            default=list(st.session_state.selected_labels),
            key=f"multiselect_{audio_file.name}_{seg_idx}"
        )
        st.session_state.selected_labels = set(selected_labels)

        # ä¿å­˜æŒ‰é’®ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨formå‡å°‘æäº¤æ¬¡æ•°ï¼‰
        col_save, col_skip = st.columns(2)
        with col_save:
            save_clicked = st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_btn_{audio_file.name}_{seg_idx}")
        with col_skip:
            skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_btn_{audio_file.name}_{seg_idx}")

        if save_clicked:
            if not selected_labels:
                st.warning("â—è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰©ç§æ ‡ç­¾ï¼")
            else:
                # ä¿å­˜åˆ†ç‰‡éŸ³é¢‘
                segment_filename = f"{os.path.splitext(audio_file.name)[0]}_seg{seg_idx}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜åˆ°CSV
                entry = {
                    "filename": audio_file.name,
                    "segment_index": segment_filename,
                    "start_time": round(start_sec, 3),
                    "end_time": round(end_sec, 3),
                    "labels": ",".join(selected_labels)
                }

                st.session_state.annotations.append(entry)
                df_combined = pd.concat([df_old, pd.DataFrame([entry])], ignore_index=True)
                df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")

                # åˆ‡æ¢åˆ†ç‰‡æˆ–ä¸‹ä¸€ä¸ªæ–‡ä»¶
                if seg_idx + 1 < total_segments:
                    st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                else:
                    st.session_state.processed_files.add(audio_file.name)
                    st.session_state.current_index += 1

                st.success("æ ‡æ³¨å·²ä¿å­˜ï¼")
                st.experimental_rerun()  # æ‰‹åŠ¨è§¦å‘åˆ·æ–°ï¼Œå‡å°‘å»¶è¿Ÿ

        if skip_clicked:
            if seg_idx + 1 < total_segments:
                st.session_state.segment_info[audio_file.name]["current_seg"] += 1
            else:
                st.session_state.processed_files.add(audio_file.name)
                st.session_state.current_index += 1
            st.experimental_rerun()

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆ
    all_done = True
    for f in uploaded_files:
        info = st.session_state.segment_info.get(f.name)
        if info is None or info["current_seg"] < info["total_seg"]:
            all_done = False
            break
    if all_done:
        st.success("ğŸ‰ æ‰€æœ‰ä¸Šä¼ çš„éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆï¼")

else:
    st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è‡³å°‘ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")
