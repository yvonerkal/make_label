import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import zipfile
from io import BytesIO
from PIL import Image
import uuid
import time
from datetime import datetime


# ======== å·¥å…·å‡½æ•°ï¼ˆæ–°å¢åŒæ­¥çº¿åŠŸèƒ½ï¼‰ =========
@st.cache_data(show_spinner=False)
def load_audio(file):
    return librosa.load(file, sr=None)


def generate_spectrogram_image(y, sr, play_pos=0.0):
    """ç”Ÿæˆå¸¦æ’­æ”¾è¿›åº¦çº¿çš„é¢‘è°±å›¾"""
    fig, ax = plt.subplots(figsize=(10, 4))  # åŠ å®½å›¾è¡¨ï¼Œé€‚åº”å•è¡Œæ˜¾ç¤º
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    
    # æ·»åŠ æ’­æ”¾è¿›åº¦çº¿ï¼ˆçº¢è‰²è™šçº¿ï¼‰
    if play_pos > 0:
        ax.axvline(x=play_pos, color='red', linestyle='--', linewidth=2, label=f'æ’­æ”¾ä½ç½®: {play_pos:.2f}s')
        ax.legend()
    
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


def generate_waveform_image(y, sr, play_pos=0.0):
    """ç”Ÿæˆå¸¦æ’­æ”¾è¿›åº¦çº¿çš„æ³¢å½¢å›¾"""
    fig, ax = plt.subplots(figsize=(10, 4))  # åŠ å®½å›¾è¡¨ï¼Œé€‚åº”å•è¡Œæ˜¾ç¤º
    librosa.display.waveshow(y, sr=sr, ax=ax)
    ax.set(title="Waveform")
    ax.set_xlim(0, librosa.get_duration(y=y, sr=sr))  # å›ºå®šxè½´èŒƒå›´ä¸ºéŸ³é¢‘æ—¶é•¿
    
    # æ·»åŠ æ’­æ”¾è¿›åº¦çº¿ï¼ˆçº¢è‰²è™šçº¿ï¼‰
    if play_pos > 0:
        ax.axvline(x=play_pos, color='red', linestyle='--', linewidth=2, label=f'æ’­æ”¾ä½ç½®: {play_pos:.2f}s')
        ax.legend()
    
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


# ======== Session çŠ¶æ€åˆå§‹åŒ–ï¼ˆæ–°å¢æ’­æ”¾çŠ¶æ€ï¼‰ =========
if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = []
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()
if "audio_state" not in st.session_state:
    st.session_state.audio_state = {
        "processed_files": set(),
        "current_index": 0,
        "segment_info": {},
        "last_audio_file": None,
        "last_seg_idx": -1,
        "annotations": []
    }
if "filtered_labels_cache" not in st.session_state:
    st.session_state.filtered_labels_cache = {}
# æ–°å¢ï¼šéŸ³é¢‘æ’­æ”¾çŠ¶æ€
if "play_state" not in st.session_state:
    st.session_state.play_state = {
        "is_playing": False,
        "start_time": 0.0,  # æ’­æ”¾å¼€å§‹çš„ç³»ç»Ÿæ—¶é—´
        "audio_duration": 0.0,  # å½“å‰ç‰‡æ®µçš„æ€»æ—¶é•¿
        "current_pos": 0.0  # å½“å‰æ’­æ”¾ä½ç½®ï¼ˆç§’ï¼‰
    }


st.set_page_config(layout="wide")
st.title("ğŸ¸ é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")


# ======== æ ‡ç­¾ç®¡ç†ç»„ä»¶ï¼ˆä¿æŒä¸å˜ï¼‰ =========
def label_management_component():
    with st.sidebar:
        st.markdown("### ğŸ·ï¸ æ ‡ç­¾è®¾ç½®")
        with st.form("label_form", clear_on_submit=True):
            label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", type=["txt"], key="label_file")
            submit_label = st.form_submit_button("åŠ è½½æ ‡ç­¾")
            if submit_label and label_file:
                try:
                    species_list = [line.strip() for line in label_file.read().decode("utf-8").split("\n") if
                                    line.strip()]
                    if species_list:
                        st.session_state["dynamic_species_list"] = species_list
                        st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(species_list)} ä¸ªæ ‡ç­¾")
                        st.rerun()
                    else:
                        st.error("æ ‡ç­¾æ–‡ä»¶ä¸ºç©º")
                except Exception as e:
                    st.error(f"é”™è¯¯ï¼š{str(e)}")
        st.markdown("#### å½“å‰æ ‡ç­¾é¢„è§ˆ")
        st.write(st.session_state["dynamic_species_list"][:5] + (
            ["..."] if len(st.session_state["dynamic_species_list"]) > 5 else []))
    return st.session_state["dynamic_species_list"]


# ======== å³ä¾§æ ‡æ³¨æ ‡ç­¾ç»„ä»¶ï¼ˆä¿æŒä¸å˜ï¼‰ =========
def annotation_labels_component(current_segment_key):
    species_list = st.session_state["dynamic_species_list"]
    col_labels = st.container()

    with col_labels:
        st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return None, None

        search_query = st.text_input("ğŸ” æœç´¢æ ‡ç­¾", "", key=f"search_{current_segment_key}")
        cache_key = f"{current_segment_key}_{search_query}"
        if cache_key not in st.session_state.filtered_labels_cache:
            st.session_state.filtered_labels_cache[cache_key] = [
                label for label in species_list if search_query.lower() in label.lower()
            ]
        filtered_species = st.session_state.filtered_labels_cache[cache_key]

        for label in filtered_species:
            key = f"label_{label}_{current_segment_key}"
            is_selected = label in st.session_state.current_selected_labels
            if st.checkbox(label, key=key, value=is_selected):
                st.session_state.current_selected_labels.add(label)
            else:
                st.session_state.current_selected_labels.discard(label)

        st.markdown("### å·²é€‰æ ‡ç­¾")
        st.info(f"å·²é€‰æ•°é‡ï¼š{len(st.session_state.current_selected_labels)}")
        if st.session_state.current_selected_labels:
            st.success(f"æ ‡ç­¾ï¼š{', '.join(st.session_state.current_selected_labels)}")
        else:
            st.info("å°šæœªé€‰æ‹©æ ‡ç­¾")

        st.markdown("### ğŸ› ï¸ æ“ä½œ")
        col_save, col_skip = st.columns(2)
        return col_save, col_skip


# ======== éŸ³é¢‘å¤„ç†é€»è¾‘ï¼ˆæ ¸å¿ƒä¼˜åŒ–éƒ¨åˆ†ï¼‰ =========
def process_audio():
    audio_state = st.session_state.audio_state
    output_dir = "uploaded_audios"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")

    # å®‰å…¨åŠ è½½CSV
    try:
        df_old = pd.read_csv(csv_path) if os.path.exists(csv_path) else pd.DataFrame(
            columns=["filename", "segment_index", "start_time", "end_time", "labels"]
        )
    except:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])

    with st.sidebar:
        st.markdown("### ğŸµ éŸ³é¢‘ä¸Šä¼ ")
        uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True, key="audio_files")
        st.markdown("### ğŸ“¥ ä¸‹è½½ç»“æœ")
        if os.path.exists(csv_path):
            with open(csv_path, "rb") as f:
                st.download_button("ğŸ“„ ä¸‹è½½CSV", f, "annotations.csv", "text/csv")
        annotated_paths = []
        if os.path.exists(csv_path) and "segment_index" in pd.read_csv(csv_path).columns:
            for _, row in pd.read_csv(csv_path).iterrows():
                try:
                    fname = str(row["segment_index"])
                    if fname and os.path.exists(os.path.join(output_dir, fname)):
                        annotated_paths.append(os.path.join(output_dir, fname))
                except:
                    pass
        if annotated_paths:
            with zipfile.ZipFile(zip_buf := BytesIO(), "w") as zf:
                for p in annotated_paths:
                    zf.write(p, os.path.basename(p))
            zip_buf.seek(0)
            st.download_button("ğŸµ ä¸‹è½½éŸ³é¢‘ç‰‡æ®µ", zip_buf, "annotated_segments.zip", "application/zip")

    if not uploaded_files:
        st.info("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return

    unprocessed = [f for f in uploaded_files if not (audio_state["segment_info"].get(f.name) and
                                                     audio_state["segment_info"][f.name]["current_seg"] >=
                                                     audio_state["segment_info"][f.name]["total_seg"])]

    if audio_state["current_index"] < len(unprocessed):
        audio_file = unprocessed[audio_state["current_index"]]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / 5.0))
        seg_idx = audio_state["segment_info"].get(audio_file.name, {"current_seg": 0})["current_seg"]
        current_segment_key = f"{audio_file.name}_{seg_idx}"

        # åˆ‡æ¢ç‰‡æ®µæ—¶é‡ç½®çŠ¶æ€
        if (audio_state["last_audio_file"] != audio_file.name or audio_state["last_seg_idx"] != seg_idx):
            st.session_state.current_selected_labels = set()
            st.session_state.play_state = {  # é‡ç½®æ’­æ”¾çŠ¶æ€
                "is_playing": False,
                "start_time": 0.0,
                "audio_duration": 0.0,
                "current_pos": 0.0
            }
            audio_state["last_audio_file"], audio_state["last_seg_idx"] = audio_file.name, seg_idx

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            st.subheader("ğŸ§ æ’­æ”¾å½“å‰ç‰‡æ®µ")
            start_sec, end_sec = seg_idx * 5.0, min((seg_idx + 1) * 5.0, total_duration)
            segment_y = y[int(start_sec * sr):int(end_sec * sr)]
            segment_duration = end_sec - start_sec  # å½“å‰ç‰‡æ®µæ—¶é•¿
            st.session_state.play_state["audio_duration"] = segment_duration  # æ›´æ–°ç‰‡æ®µæ—¶é•¿

            # ç”ŸæˆéŸ³é¢‘å­—èŠ‚æµï¼ˆç”¨äºæ’­æ”¾ï¼‰
            audio_bytes = BytesIO()
            sf.write(audio_bytes, segment_y, sr, format='WAV')
            audio_bytes.seek(0)

            # æ’­æ”¾æ§åˆ¶ä¸è¿›åº¦åŒæ­¥
            play_col1, play_col2 = st.columns([1, 5])
            with play_col1:
                # æ’­æ”¾/æš‚åœæŒ‰é’®
                if st.button("â–¶ï¸ æ’­æ”¾" if not st.session_state.play_state["is_playing"] else "â¸ï¸ æš‚åœ", 
                            key=f"play_btn_{current_segment_key}"):
                    st.session_state.play_state["is_playing"] = not st.session_state.play_state["is_playing"]
                    if st.session_state.play_state["is_playing"]:
                        # è®°å½•å¼€å§‹æ’­æ”¾æ—¶é—´ï¼ˆæ‰£é™¤å·²æ’­æ”¾æ—¶é•¿ï¼‰
                        st.session_state.play_state["start_time"] = time.time() - st.session_state.play_state["current_pos"]
                    else:
                        # æš‚åœæ—¶è®°å½•å½“å‰ä½ç½®
                        st.session_state.play_state["current_pos"] = min(
                            time.time() - st.session_state.play_state["start_time"],
                            segment_duration
                        )

            with play_col2:
                # æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨ï¼ˆéšè—åŸç”Ÿè¿›åº¦æ¡ï¼Œä½¿ç”¨è‡ªå®šä¹‰åŒæ­¥çº¿ï¼‰
                st.audio(audio_bytes, format="audio/wav", start_time=0, loop=False)

            # æ³¢å½¢å›¾å’Œé¢‘è°±å›¾ï¼ˆæ”¹ä¸ºä¸¤è¡Œæ˜¾ç¤ºï¼Œå¹¶æ·»åŠ åŒæ­¥çº¿ï¼‰
            # 1. æ³¢å½¢å›¾ï¼ˆç¬¬ä¸€è¡Œï¼‰
            st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
            wave_placeholder = st.empty()  # æ³¢å½¢å›¾å ä½ç¬¦ï¼Œç”¨äºåŠ¨æ€æ›´æ–°

            # 2. é¢‘è°±å›¾ï¼ˆç¬¬äºŒè¡Œï¼‰
            st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
            spec_placeholder = st.empty()  # é¢‘è°±å›¾å ä½ç¬¦ï¼Œç”¨äºåŠ¨æ€æ›´æ–°

            # å®æ—¶æ›´æ–°å›¾è¡¨ï¼ˆä»…åœ¨æ’­æ”¾æ—¶ï¼‰
            if st.session_state.play_state["is_playing"]:
                # è®¡ç®—å½“å‰æ’­æ”¾ä½ç½®
                current_pos = min(
                    time.time() - st.session_state.play_state["start_time"],
                    segment_duration
                )
                st.session_state.play_state["current_pos"] = current_pos

                # æ›´æ–°æ³¢å½¢å›¾ï¼ˆå¸¦åŒæ­¥çº¿ï¼‰
                wave_img = generate_waveform_image(segment_y, sr, play_pos=current_pos)
                wave_placeholder.image(wave_img, caption="Waveform", use_container_width=True)

                # æ›´æ–°é¢‘è°±å›¾ï¼ˆå¸¦åŒæ­¥çº¿ï¼‰
                spec_img = generate_spectrogram_image(segment_y, sr, play_pos=current_pos)
                spec_placeholder.image(spec_img, caption="Spectrogram (dB)", use_container_width=True)

                # æ’­æ”¾ç»“æŸåé‡ç½®çŠ¶æ€
                if current_pos >= segment_duration:
                    st.session_state.play_state["is_playing"] = False
                    st.session_state.play_state["current_pos"] = 0.0
                    st.rerun()  # åˆ·æ–°é¡µé¢æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€

            else:
                # æœªæ’­æ”¾æ—¶æ˜¾ç¤ºé™æ€å›¾è¡¨ï¼ˆå¸¦æœ€åä½ç½®çº¿æˆ–æ— çº¿ï¼‰
                wave_img = generate_waveform_image(
                    segment_y, sr, 
                    play_pos=st.session_state.play_state["current_pos"]
                )
                wave_placeholder.image(wave_img, caption="Waveform", use_container_width=True)

                spec_img = generate_spectrogram_image(
                    segment_y, sr, 
                    play_pos=st.session_state.play_state["current_pos"]
                )
                spec_placeholder.image(spec_img, caption="Spectrogram (dB)", use_container_width=True)

        with col_labels:
            col_save, col_skip = annotation_labels_component(current_segment_key)

            if col_save and col_skip:
                with col_save:
                    if st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_{current_segment_key}"):
                        try:
                            if not st.session_state.current_selected_labels:
                                st.warning("â—è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾")
                                return

                            os.makedirs(output_dir, exist_ok=True)
                            base_name = os.path.splitext(audio_file.name)[0]
                            unique_id = uuid.uuid4().hex[:8]
                            segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
                            segment_path = os.path.join(output_dir, segment_filename)

                            # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                            with sf.SoundFile(segment_path, 'w', samplerate=sr, channels=1) as f:
                                f.write(segment_y)

                            # ä¿å­˜CSV
                            clean_labels = [label.replace("/", "").replace("\\", "") for label in
                                            st.session_state.current_selected_labels]
                            entry = {
                                "filename": audio_file.name,
                                "segment_index": segment_filename,
                                "start_time": round(start_sec, 3),
                                "end_time": round(end_sec, 3),
                                "labels": ",".join(clean_labels)
                            }
                            new_df = pd.DataFrame([entry])
                            combined_df = pd.concat([df_old, new_df], ignore_index=True) if not df_old.empty else new_df
                            combined_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

                            # æ›´æ–°çŠ¶æ€
                            if seg_idx + 1 < total_segments:
                                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                            else:
                                audio_state["processed_files"].add(audio_file.name)
                                audio_state["current_index"] += 1

                            st.success(f"æˆåŠŸä¿å­˜æ ‡æ³¨ï¼æ–‡ä»¶: {segment_filename}")
                            st.rerun()

                        except Exception as e:
                            st.error(f"ä¿å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

                with col_skip:
                    if st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_{current_segment_key}"):
                        if seg_idx + 1 < total_segments:
                            audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                        else:
                            audio_state["processed_files"].add(audio_file.name)
                            audio_state["current_index"] += 1
                        st.rerun()

    else:
        st.success("ğŸ‰ æ‰€æœ‰éŸ³é¢‘æ ‡æ³¨å®Œæˆï¼")

    st.session_state.audio_state = audio_state


# ======== ä¸»æµç¨‹ =========
if __name__ == "__main__":
    label_management_component()
    process_audio()
