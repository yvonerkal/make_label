# ä¿å­˜ã€ä¸‹è½½æ•°æ®çš„æ–¹å¼
# é¢‘è°±å›¾æ˜¾ç¤ºé—®é¢˜
# ä¿å­˜åˆ†å‰²æ•°æ®æ—¶ï¼Œå¼€å§‹æ—¶é—´ç‚¹å¾€å‰ï¼Œç»“æŸæ—¶é—´ç‚¹å¾€åå–æ•´
import streamlit as st
from streamlit_drawable_canvas import st_canvas
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import zipfile
from io import BytesIO
from PIL import Image
import uuid
from pypinyin import lazy_pinyin
import sys

sys.setrecursionlimit(10000)  # å¢åŠ é€’å½’æ·±åº¦é™åˆ¶


# ======== å·¥å…·å‡½æ•° =========
@st.cache_data(show_spinner=False)
def load_audio(file):
    return librosa.load(file, sr=None)


def generate_spectrogram_data(y, sr):
    """ç”Ÿæˆé¢‘è°±å›¾æ•°æ®åŠåæ ‡è½´èŒƒå›´ï¼ˆç”¨äºåæ ‡è½¬æ¢ï¼‰"""
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    times = librosa.times_like(D, sr=sr)  # æ—¶é—´è½´ï¼š0-5ç§’ï¼ˆ5ç§’ç‰‡æ®µï¼‰
    frequencies = librosa.fft_frequencies(sr=sr)  # é¢‘ç‡è½´ï¼š0åˆ°sr/2ï¼ˆå¥ˆå¥æ–¯ç‰¹é¢‘ç‡ï¼‰
    return D, times, frequencies


def generate_spectrogram_image(D, times, frequencies):
    """ç”Ÿæˆå¸¦åæ ‡çš„é¢‘è°±å›¾ï¼ˆç¡®ä¿x/yè½´èŒƒå›´æ˜ç¡®ï¼‰"""
    fig, ax = plt.subplots(figsize=(12, 6), dpi=100)  # å›ºå®šå°ºå¯¸
    img = librosa.display.specshow(
        D,
        sr=frequencies[-1] * 2,
        x_axis='time',
        y_axis='log',
        ax=ax
    )
    ax.set_xlim(times[0], times[-1])
    ax.set_ylim(frequencies[0], frequencies[-1])
    ax.set_title('é¢‘è°±å›¾ï¼ˆå¯ç”»æ¡†æ ‡æ³¨ï¼‰')
    fig.colorbar(img, ax=ax, format='%+2.0f dB')
    fig.tight_layout()

    buf = io.BytesIO()
    # ğŸ‘‰ æ”¹ä¸ºç™½åº•ä¸é€æ˜èƒŒæ™¯ï¼ˆåŠ  facecolor='white'ï¼‰
    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1, facecolor='white')
    buf.seek(0)
    plt.close(fig)
    if img.mode != "RGB":
        img = img.convert("RGB")


    return Image.open(buf)



@st.cache_data(show_spinner=False)
def generate_waveform_image(y, sr):
    plt.figure(figsize=(12, 3), dpi=100)
    librosa.display.waveshow(y, sr=sr)
    plt.title('æ³¢å½¢å›¾')
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    plt.close()
    return Image.open(buf)


def get_pinyin_abbr(text):
    return ''.join([p[0] for p in lazy_pinyin(text) if p])


def get_full_pinyin(text):
    return ''.join(lazy_pinyin(text))


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = []
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()
if "audio_state" not in st.session_state:
    st.session_state.audio_state = {
        "processed_files": set(),
        "current_index": 0,
        "segment_info": {},
        "last_audio_file": None,
        "last_seg_idx": -1,
    }
if "filtered_labels_cache" not in st.session_state:
    st.session_state.filtered_labels_cache = {}
if "canvas_boxes" not in st.session_state:  # å­˜å‚¨å¸¦æ ‡ç­¾çš„ç”»æ¡†ï¼š{åƒç´ åæ ‡, æ—¶é—´é¢‘ç‡, æ ‡ç­¾}
    st.session_state.canvas_boxes = []
if "spec_params" not in st.session_state:  # å­˜å‚¨é¢‘è°±å›¾å‚æ•°ï¼ˆç”¨äºåæ ‡è½¬æ¢ï¼‰
    st.session_state.spec_params = {"times": None, "frequencies": None, "img_size": (0, 0)}
if "spec_image" not in st.session_state:  # ç¼“å­˜é¢‘è°±å›¾ä»¥é¿å…é‡å¤ç”Ÿæˆ
    st.session_state.spec_image = None

st.set_page_config(layout="wide")
st.title("ğŸ¸ é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")


# ======== æ ‡ç­¾ç®¡ç†ç»„ä»¶ =========
def label_management_component():
    with st.sidebar:
        st.markdown("### ğŸ·ï¸ æ ‡ç­¾è®¾ç½®")
        with st.form("label_form", clear_on_submit=True):
            label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", type=["txt"], key="label_file")
            submit_label = st.form_submit_button("åŠ è½½æ ‡ç­¾")
            if submit_label and label_file:
                try:
                    species_list = [line.strip() for line in label_file.read().decode("utf-8").split("\n") if
                                    line.strip()]
                    st.session_state["dynamic_species_list"] = species_list
                    st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(species_list)} ä¸ªæ ‡ç­¾")
                    st.rerun()
                except Exception as e:
                    st.error(f"é”™è¯¯ï¼š{str(e)}")
        st.markdown("#### å½“å‰æ ‡ç­¾é¢„è§ˆ")
        st.write(st.session_state["dynamic_species_list"][:5] + (
            ["..."] if len(st.session_state["dynamic_species_list"]) > 5 else []))

        # æ ‡æ³¨æ¨¡å¼é€‰æ‹©
        st.session_state.annotation_mode = st.radio(
            "æ ‡æ³¨æ¨¡å¼",
            ["åˆ†æ®µæ ‡æ³¨", "é¢‘è°±å›¾ç”»æ¡†"],
            index=0 if st.session_state.get("annotation_mode") == "åˆ†æ®µæ ‡æ³¨" else 1
        )
    return st.session_state["dynamic_species_list"]


# ======== é¢‘è°±å›¾ç”»æ¡†+æ ‡ç­¾å…³è”ç»„ä»¶ =========
def spectral_annotation_component(y, sr, current_segment_key):
    # ç”Ÿæˆé¢‘è°±å›¾æ•°æ®ï¼ˆæ—¶é—´ã€é¢‘ç‡èŒƒå›´ï¼‰
    D, times, frequencies = generate_spectrogram_data(y, sr)

    # ç¼“å­˜é¢‘è°±å›¾ï¼Œé¿å…é‡å¤ç”Ÿæˆ
    if st.session_state.spec_image is None:
        spec_image = generate_spectrogram_image(D, times, frequencies)
        st.session_state.spec_image = spec_image
    else:
        spec_image = st.session_state.spec_image

    st.session_state.spec_params = {
        "times": times,  # 0-5ç§’çš„æ—¶é—´è½´
        "frequencies": frequencies,  # é¢‘ç‡è½´ï¼ˆ0åˆ°sr/2ï¼‰
        "img_size": (spec_image.width, spec_image.height)  # é¢‘è°±å›¾å°ºå¯¸ï¼ˆåƒç´ ï¼‰
    }

    # ä¸»åŒºåŸŸå¸ƒå±€ï¼šå·¦ä¾§ä¸ºæ“ä½œåŒºï¼ˆå›ºå®šç»“æ„ï¼‰ï¼Œå³ä¾§ä¸ºæ ‡ç­¾åŒºï¼ˆå¯æ»šåŠ¨ï¼‰
    col_main, col_labels = st.columns([3, 1])

    with col_main:
        st.subheader("ğŸ§ é¢‘è°±å›¾ç”»æ¡†æ ‡æ³¨ï¼ˆç‚¹å‡»ç”»å¸ƒç»˜åˆ¶çŸ©å½¢ï¼‰")
        

        # 1. éŸ³é¢‘æ’­æ”¾ç§»åˆ°é¢‘è°±å›¾ä¸Šæ–¹
        st.markdown("#### éŸ³é¢‘æ’­æ”¾")
        audio_bytes = BytesIO()
        sf.write(audio_bytes, y, sr, format='WAV')
        st.audio(audio_bytes, format="audio/wav", start_time=0)

        # 2. é¢‘è°±å›¾ç”»å¸ƒåŒºåŸŸ
        # DEBUG: ä¸´æ—¶æ˜¾ç¤ºé¢‘è°±å›¾
        st.image(spec_image, caption="é¢‘è°±å›¾ DEBUG æ˜¾ç¤º", use_column_width=True)
        st.markdown("#### é¢‘è°±å›¾ï¼ˆå¯ç»˜åˆ¶çŸ©å½¢æ¡†ï¼‰")
        canvas_result = st_canvas(
            fill_color="rgba(255, 0, 0, 0.3)",  # åŠé€æ˜æ©™è‰²
            stroke_width=2,
            stroke_color="#FF0000",  # çº¢è‰²è¾¹æ¡†
            background_color="#eee",
            background_image=spec_image,
            height=spec_image.height,  # ç”»å¸ƒé«˜åº¦=é¢‘è°±å›¾é«˜åº¦
            width=spec_image.width,  # ç”»å¸ƒå®½åº¦=é¢‘è°±å›¾å®½åº¦
            drawing_mode="rect",  # ä»…å…è®¸ç”»çŸ©å½¢
            key=f"canvas_{current_segment_key}",
            update_streamlit=True,  # å¯ç”¨è‡ªåŠ¨æ›´æ–°
            display_toolbar=True  # æ˜¾ç¤ºå·¥å…·æ 
        )

        # å¤„ç†ç”»å¸ƒä¸Šçš„ç”»æ¡†
        if canvas_result.json_data is not None:
            st.session_state.canvas_boxes = [
                {
                    "pixel": {  # åƒç´ åæ ‡ï¼ˆç”»å¸ƒä¸Šçš„ä½ç½®ï¼‰
                        "left": obj["left"],
                        "top": obj["top"],
                        "width": obj["width"],
                        "height": obj["height"]
                    },
                    "label": None  # åˆå§‹æ— æ ‡ç­¾
                }
                for obj in canvas_result.json_data["objects"]
                if obj["type"] == "rect"
            ]

        # 3. åˆ·æ–°æŒ‰é’®å’Œæ“ä½œæŒ‰é’®ç»„ï¼ˆå›ºå®šåœ¨é¢‘è°±å›¾ä¸‹æ–¹ï¼‰
        st.markdown("#### æ“ä½œ")
        button_row = st.columns([1, 1, 2])  # è°ƒæ•´æŒ‰é’®å®½åº¦æ¯”ä¾‹
        with button_row[0]:
            refresh_clicked = st.button("åˆ·æ–°é¢‘è°±å›¾", key="refresh_spec")
        with button_row[1]:
            save_clicked = st.button("ä¿å­˜ç”»æ¡†æ ‡æ³¨", key=f"save_boxes_{current_segment_key}")
        with button_row[2]:
            skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_box_{current_segment_key}")

        # å¤„ç†åˆ·æ–°é€»è¾‘
        if refresh_clicked:
            st.session_state.spec_image = None
            st.rerun()

    # å³ä¾§æ ‡ç­¾ç®¡ç†åŒºåŸŸï¼ˆå¯æ»šåŠ¨ï¼Œä¸å½±å“å·¦ä¾§æŒ‰é’®ä½ç½®ï¼‰
    with col_labels:
        st.markdown("### æ¡†æ ‡ç­¾ç®¡ç†")
        species_list = st.session_state["dynamic_species_list"]
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return save_clicked, skip_clicked

        # æ˜¾ç¤ºæ‰€æœ‰ç”»æ¡†å¹¶å…³è”æ ‡ç­¾
        if st.session_state.canvas_boxes:
            for i, box in enumerate(st.session_state.canvas_boxes):
                st.markdown(f"#### æ¡† {i + 1}")

                # è½¬æ¢åƒç´ åæ ‡ä¸ºå®é™…æ—¶é—´å’Œé¢‘ç‡
                time_freq = pixel_to_time_freq(box["pixel"])
                st.write(f"æ—¶é—´èŒƒå›´ï¼š{time_freq['start']:.2f} - {time_freq['end']:.2f} ç§’")
                st.write(f"é¢‘ç‡èŒƒå›´ï¼š{time_freq['min']:.0f} - {time_freq['max']:.0f} Hz")

                # ä¸ºå½“å‰æ¡†é€‰æ‹©æ ‡ç­¾
                search_query = st.text_input(
                    "æœç´¢æ ‡ç­¾", "", key=f"box_search_{i}",
                    placeholder="è¾“å…¥ä¸­æ–‡/æ‹¼éŸ³é¦–å­—æ¯"
                )
                # è¿‡æ»¤æ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡ã€æ‹¼éŸ³é¦–å­—æ¯ã€å…¨æ‹¼ï¼‰
                filtered = []
                if search_query:
                    q = search_query.lower()
                    for label in species_list:
                        if q in label.lower() or q in get_pinyin_abbr(label).lower() or q in get_full_pinyin(
                                label).lower():
                            filtered.append(label)
                else:
                    filtered = species_list

                # é€‰æ‹©æ ‡ç­¾å¹¶ä¿å­˜
                selected_label = st.selectbox(
                    f"é€‰æ‹©æ¡† {i + 1} çš„æ ‡ç­¾",
                    filtered,
                    index=filtered.index(box["label"]) if box["label"] in filtered else 0,
                    key=f"box_label_{i}"
                )
                # æ›´æ–°å½“å‰æ¡†çš„æ ‡ç­¾
                if selected_label != box["label"]:
                    st.session_state.canvas_boxes[i]["label"] = selected_label
                    st.session_state.canvas_boxes = st.session_state.canvas_boxes  # è§¦å‘çŠ¶æ€æ›´æ–°

    return save_clicked, skip_clicked


# ======== åƒç´ åæ ‡â†’æ—¶é—´/é¢‘ç‡è½¬æ¢å‡½æ•° =========
def pixel_to_time_freq(pixel_coords):
    """å°†ç”»å¸ƒä¸Šçš„åƒç´ åæ ‡è½¬æ¢ä¸ºå®é™…çš„æ—¶é—´ï¼ˆç§’ï¼‰å’Œé¢‘ç‡ï¼ˆHzï¼‰"""
    times = st.session_state.spec_params["times"]
    frequencies = st.session_state.spec_params["frequencies"]
    img_width, img_height = st.session_state.spec_params["img_size"]

    # æ—¶é—´èŒƒå›´ï¼ˆxè½´ï¼‰ï¼šç”»å¸ƒå·¦â†’å³ = 0â†’5ç§’
    total_time = times[-1] - times[0]  # æ€»æ—¶é•¿ï¼ˆ5ç§’ï¼‰
    time_per_pixel = total_time / img_width  # æ¯ä¸ªåƒç´ å¯¹åº”çš„æ—¶é—´
    start_time = times[0] + pixel_coords["left"] * time_per_pixel
    end_time = start_time + pixel_coords["width"] * time_per_pixel

    # é¢‘ç‡èŒƒå›´ï¼ˆyè½´ï¼‰ï¼šç”»å¸ƒä¸Šâ†’ä¸‹ = é«˜é¢‘â†’ä½é¢‘ï¼ˆå› ä¸ºé¢‘è°±å›¾yè½´æ˜¯å€’çš„ï¼‰
    total_freq = frequencies[-1] - frequencies[0]  # æ€»é¢‘ç‡èŒƒå›´ï¼ˆ0åˆ°sr/2ï¼‰
    freq_per_pixel = total_freq / img_height  # æ¯ä¸ªåƒç´ å¯¹åº”çš„é¢‘ç‡
    max_freq = frequencies[-1] - pixel_coords["top"] * freq_per_pixel
    min_freq = max_freq - pixel_coords["height"] * freq_per_pixel

    return {
        "start": round(max(0, start_time), 3),  # ç¡®ä¿ä¸å°äº0
        "end": round(min(5, end_time), 3),  # ç¡®ä¿ä¸è¶…è¿‡5ç§’
        "min": round(max(0, min_freq), 1),
        "max": round(min(frequencies[-1], max_freq), 1)
    }


# ======== éŸ³é¢‘å¤„ç†ä¸»é€»è¾‘ =========
def process_audio():
    audio_state = st.session_state.audio_state
    output_dir = "annotated_audios"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")

    # åˆå§‹åŒ–CSVï¼ˆåŒ…å«ç”»æ¡†çš„æ—¶é—´ã€é¢‘ç‡ã€æ ‡ç­¾ï¼‰
    try:
        if not os.path.exists(csv_path):
            pd.DataFrame(columns=[
                "filename", "segment_index", "box_id",
                "start_time", "end_time", "min_freq", "max_freq", "label"
            ]).to_csv(csv_path, index=False, encoding='utf_8_sig')
        try:
            df_old = pd.read_csv(csv_path, encoding='utf_8_sig')
        except Exception as e:
            st.error(f"CSVæ–‡ä»¶é”™è¯¯ï¼š{str(e)}")
            return
    except Exception as e:
        st.error(f"CSVæ–‡ä»¶é”™è¯¯ï¼š{str(e)}")
        return

    with st.sidebar:
        st.markdown("### ğŸµ éŸ³é¢‘ä¸Šä¼ ")
        uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True, key="audio_files")
        st.markdown("### ğŸ“¥ ä¸‹è½½ç»“æœ")
        if os.path.exists(csv_path):
            with open(csv_path, "rb") as f:
                st.download_button("ğŸ“„ ä¸‹è½½æ ‡æ³¨ç»“æœ", f, "annotations.csv", "text/csv; charset=utf-8")
        if os.path.exists(output_dir):
            with zipfile.ZipFile(zip_buf := BytesIO(), "w") as zf:
                for f in os.listdir(output_dir):
                    if f.endswith(".wav"):
                        zf.write(os.path.join(output_dir, f), f)
            zip_buf.seek(0)
            st.download_button("ğŸµ ä¸‹è½½éŸ³é¢‘ç‰‡æ®µ", zip_buf, "annotated_segments.zip", "application/zip")

    if not uploaded_files:
        st.info("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return

    # è·å–æœªå¤„ç†çš„éŸ³é¢‘
    unprocessed = [f for f in uploaded_files if f.name not in audio_state["processed_files"]]

    if unprocessed:
        audio_file = unprocessed[0]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / 5.0))

        # åˆå§‹åŒ–å½“å‰éŸ³é¢‘çš„åˆ†æ®µä¿¡æ¯
        if audio_file.name not in audio_state["segment_info"]:
            audio_state["segment_info"][audio_file.name] = {"current_seg": 0, "total_seg": total_segments}
        seg_idx = audio_state["segment_info"][audio_file.name]["current_seg"]
        current_segment_key = f"{audio_file.name}_{seg_idx}"

        # åˆ‡æ¢éŸ³é¢‘/åˆ†æ®µæ—¶é‡ç½®çŠ¶æ€
        if (audio_state["last_audio_file"] != audio_file.name or
                audio_state["last_seg_idx"] != seg_idx):
            st.session_state.current_selected_labels = set()
            st.session_state.canvas_boxes = []
            st.session_state.spec_image = None  # é‡ç½®é¢‘è°±å›¾ç¼“å­˜
            audio_state["last_audio_file"] = audio_file.name
            audio_state["last_seg_idx"] = seg_idx

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")
        start_sec, end_sec = seg_idx * 5.0, min((seg_idx + 1) * 5.0, total_duration)
        segment_y = y[int(start_sec * sr):int(end_sec * sr)]  # å½“å‰5ç§’ç‰‡æ®µ

        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ ‡æ³¨æ–¹å¼
        if st.session_state.annotation_mode == "é¢‘è°±å›¾ç”»æ¡†":
            save_clicked, skip_clicked = spectral_annotation_component(segment_y, sr, current_segment_key)

            # ä¿å­˜ç”»æ¡†æ ‡æ³¨
            if save_clicked:
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¡†éƒ½æœ‰æ ‡ç­¾
                if not st.session_state.canvas_boxes:
                    st.warning("è¯·å…ˆç»˜åˆ¶è‡³å°‘ä¸€ä¸ªæ¡†")
                    return
                if any(box["label"] is None for box in st.session_state.canvas_boxes):
                    st.warning("è¯·ä¸ºæ‰€æœ‰æ¡†æ·»åŠ æ ‡ç­¾")
                    return

                # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                base_name = os.path.splitext(audio_file.name)[0]
                unique_id = uuid.uuid4().hex[:8]
                segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜æ¯ä¸ªæ¡†çš„ä¿¡æ¯åˆ°CSV
                entries = []
                for box_id, box in enumerate(st.session_state.canvas_boxes):
                    time_freq = pixel_to_time_freq(box["pixel"])
                    entries.append({
                        "filename": audio_file.name,
                        "segment_index": segment_filename,
                        "box_id": box_id,
                        "start_time": time_freq["start"],
                        "end_time": time_freq["end"],
                        "min_freq": time_freq["min"],
                        "max_freq": time_freq["max"],
                        "label": box["label"]
                    })
                pd.DataFrame(entries).to_csv(csv_path, mode='a', header=False, index=False, encoding='utf_8_sig')

                # æ›´æ–°çŠ¶æ€ï¼Œè¿›å…¥ä¸‹ä¸€æ®µ
                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                    audio_state["processed_files"].add(audio_file.name)
                st.session_state.spec_image = None  # é‡ç½®é¢‘è°±å›¾ç¼“å­˜
                st.success(f"æˆåŠŸä¿å­˜ {len(entries)} ä¸ªæ¡†æ ‡æ³¨ï¼")
                st.balloons()
                st.rerun()

            # è·³è¿‡å½“å‰æ®µ
            if skip_clicked:
                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                    audio_state["processed_files"].add(audio_file.name)
                st.session_state.spec_image = None  # é‡ç½®é¢‘è°±å›¾ç¼“å­˜
                st.rerun()

        else:
            # åŸæœ‰åˆ†æ®µæ ‡æ³¨é€»è¾‘
            col_main, col_labels = st.columns([3, 1])
            with col_main:
                st.subheader("ğŸ§ æ’­æ”¾å½“å‰ç‰‡æ®µ")
                audio_bytes = BytesIO()
                sf.write(audio_bytes, segment_y, sr, format='WAV')
                st.audio(audio_bytes, format="audio/wav")
                col1, col2 = st.columns(2)
                with col1:
                    st.image(generate_waveform_image(segment_y, sr), caption="æ³¢å½¢å›¾", use_container_width=True)
                with col2:
                    st.image(generate_spectrogram_image(*generate_spectrogram_data(segment_y, sr)), caption="é¢‘è°±å›¾",
                             use_container_width=True)

            with col_labels:
                col_save, col_skip = annotation_labels_component(current_segment_key)
                if col_save and st.button("ä¿å­˜åˆ†æ®µæ ‡æ³¨", key=f"save_seg_{current_segment_key}"):
                    save_segment_annotation(audio_file, seg_idx, start_sec, end_sec, segment_y, sr, output_dir)
                if col_skip and st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_seg_{current_segment_key}"):
                    audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                    if audio_state["segment_info"][audio_file.name]["current_seg"] >= total_segments:
                        audio_state["processed_files"].add(audio_file.name)
                    st.rerun()

    else:
        st.success("ğŸ‰ æ‰€æœ‰éŸ³é¢‘æ ‡æ³¨å®Œæˆï¼")

    st.session_state.audio_state = audio_state


# ======== åˆ†æ®µæ ‡æ³¨ä¿å­˜å‡½æ•° =========
def save_segment_annotation(audio_file, seg_idx, start_sec, end_sec, segment_y, sr, output_dir):
    csv_path = os.path.join(output_dir, "annotations.csv")
    if not st.session_state.current_selected_labels:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾")
        return

    base_name = os.path.splitext(audio_file.name)[0]
    unique_id = uuid.uuid4().hex[:8]
    segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
    segment_path = os.path.join(output_dir, segment_filename)
    sf.write(segment_path, segment_y, sr)

    entry = {
        "filename": audio_file.name,
        "segment_index": segment_filename,
        "box_id": None,
        "start_time": round(start_sec, 3),
        "end_time": round(end_sec, 3),
        "min_freq": None,
        "max_freq": None,
        "label": ",".join(st.session_state.current_selected_labels)
    }
    pd.DataFrame([entry]).to_csv(csv_path, mode='a', header=False, index=False, encoding='utf_8_sig')

    audio_state = st.session_state.audio_state
    audio_state["segment_info"][audio_file.name]["current_seg"] += 1
    if audio_state["segment_info"][audio_file.name]["current_seg"] >= audio_state["segment_info"][audio_file.name][
        "total_seg"]:
        audio_state["processed_files"].add(audio_file.name)
    st.success(f"æˆåŠŸä¿å­˜åˆ†æ®µæ ‡æ³¨ï¼")
    st.balloons()
    st.rerun()


# ======== åŸæœ‰åˆ†æ®µæ ‡æ³¨æ ‡ç­¾ç»„ä»¶ =========
def annotation_labels_component(current_segment_key):
    species_list = st.session_state["dynamic_species_list"]
    col_labels = st.container()

    with col_labels:
        st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return None, None

        search_query = st.text_input("ğŸ” æœç´¢æ ‡ç­¾", "", key=f"search_{current_segment_key}")
        cache_key = f"{current_segment_key}_{search_query}"

        if cache_key not in st.session_state.filtered_labels_cache:
            filtered_species = []
            if search_query:
                search_lower = search_query.lower()
                for label in species_list:
                    if (search_lower in label.lower() or
                            search_lower in get_pinyin_abbr(label) or
                            search_lower in get_full_pinyin(label)):
                        filtered_species.append(label)
            else:
                filtered_species = species_list.copy()
            st.session_state.filtered_labels_cache[cache_key] = filtered_species

        filtered_species = st.session_state.filtered_labels_cache[cache_key]
        for label in filtered_species:
            key = f"label_{label}_{current_segment_key}"
            is_selected = label in st.session_state.current_selected_labels
            if st.checkbox(label, key=key, value=is_selected):
                st.session_state.current_selected_labels.add(label)
            else:
                st.session_state.current_selected_labels.discard(label)

        st.markdown("### å·²é€‰æ ‡ç­¾")
        st.info(f"å·²é€‰æ•°é‡ï¼š{len(st.session_state.current_selected_labels)}")
        col_save, col_skip = st.columns(2)
        return col_save, col_skip


if __name__ == "__main__":
    label_management_component()
    process_audio()
