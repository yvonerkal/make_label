import streamlit as st
from streamlit_drawable_canvas import st_canvas
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import uuid
from PIL import Image
import zipfile
from io import BytesIO
import hashlib  # ç”¨äºç”ŸæˆéŸ³é¢‘æ•°æ®çš„å”¯ä¸€å“ˆå¸Œå€¼


# å·¥å…·å‡½æ•°ä¼˜åŒ–ï¼šè§£å†³å›¾è¡¨ç¼“å­˜å’Œé—ªç°é—®é¢˜
# ======== å·¥å…·å‡½æ•° =========
@st.cache_data
def load_audio(file):
    # ä¸ºä¸åŒæ–‡ä»¶ç”Ÿæˆå”¯ä¸€ç¼“å­˜é”®
    file_key = hashlib.md5(file.getvalue()).hexdigest()
    return librosa.load(file, sr=None)


def generate_spectrogram_image(y, sr, unique_key):
    """ç”Ÿæˆé¢‘è°±å›¾ï¼Œæ·»åŠ unique_keyç¡®ä¿ç¼“å­˜å”¯ä¸€"""
    # å¼ºåˆ¶æ¸…é™¤Matplotlibæ®‹ç•™çŠ¶æ€
    plt.close('all')
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    
    # ä½¿ç”¨BytesIOå­˜å‚¨å›¾è¡¨ï¼Œé¿å…æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)  # ç¡®ä¿å…³é—­å½“å‰å›¾è¡¨
    return Image.open(buf)


def generate_waveform_image(y, sr, unique_key):
    """ç”Ÿæˆæ³¢å½¢å›¾ï¼Œæ·»åŠ unique_keyç¡®ä¿ç¼“å­˜å”¯ä¸€"""
    # å¼ºåˆ¶æ¸…é™¤Matplotlibæ®‹ç•™çŠ¶æ€
    plt.close('all')
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    fig.tight_layout()
    
    # ä½¿ç”¨BytesIOå­˜å‚¨å›¾è¡¨ï¼Œé¿å…æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)  # ç¡®ä¿å…³é—­å½“å‰å›¾è¡¨
    return Image.open(buf)


def is_fully_annotated(file):
    info = st.session_state.segment_info.get(file.name)
    if info is None:
        return False
    return info["current_seg"] >= info["total_seg"]


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "segment_info" not in st.session_state:
    st.session_state.segment_info = {}
if "last_audio_file" not in st.session_state:
    st.session_state.last_audio_file = None
if "last_seg_idx" not in st.session_state:
    st.session_state.last_seg_idx = -1
# æ·»åŠ å›¾è¡¨ç¼“å­˜çŠ¶æ€ï¼Œé¿å…é‡å¤ç”Ÿæˆ
if "plot_cache" not in st.session_state:
    st.session_state.plot_cache = {}


st.set_page_config(layout="wide")
st.title("é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")


# ======== ä¾§è¾¹æ  =========
with st.sidebar:
    uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True)
    output_dir = st.text_input("ä¿å­˜ç›®å½•", "E:/Frog audio classification/uploaded_audios")
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")
    if os.path.exists(csv_path):
        df_old = pd.read_csv(csv_path, encoding="utf-8")
    else:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])


    # ä¸‹è½½åŒºåŸŸ
    st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡æ³¨ç»“æœ")
    if os.path.exists(csv_path):
        with open(csv_path, "rb") as f:
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ ‡æ³¨CSVæ–‡ä»¶",
                data=f,
                file_name="annotations.csv",
                mime="text/csv"
            )


    # éŸ³é¢‘ç‰‡æ®µä¸‹è½½ï¼ˆä¼˜åŒ–é”™è¯¯å¤„ç†ï¼‰
    annotated_paths = []
    if os.path.exists(csv_path):
        df_tmp = pd.read_csv(csv_path)
        if "segment_index" in df_tmp.columns:
            for idx, row in df_tmp.iterrows():
                try:
                    fname = str(row["segment_index"])
                    if pd.notna(fname) and fname.strip():
                        full_path = os.path.join(output_dir, fname)
                        if os.path.exists(full_path):
                            annotated_paths.append(full_path)
                except Exception as e:
                    st.warning(f"å¤„ç†è·¯å¾„æ—¶å‡ºé”™: {str(e)}")
        else:
            st.warning("CSVæ–‡ä»¶ç¼ºå°‘ 'segment_index' åˆ—ï¼Œæ— æ³•ç”ŸæˆéŸ³é¢‘åŒ…")


    if annotated_paths:
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zip_file:
            for path in annotated_paths:
                zip_file.write(path, os.path.basename(path))
        zip_buffer.seek(0)
        st.download_button(
            label="ğŸµ ä¸‹è½½æ ‡æ³¨éŸ³é¢‘ (ZIP)",
            data=zip_buffer,
            file_name="annotated_audio_segments.zip",
            mime="application/zip"
        )


    # æ ‡æ³¨çŠ¶æ€æ˜¾ç¤º
    if uploaded_files:
        with st.expander("âœ… å·²æ ‡æ³¨éŸ³é¢‘", expanded=True):
            st.write([f.name for f in uploaded_files if f.name in st.session_state.processed_files])
        with st.expander("ğŸ•“ æœªæ ‡æ³¨éŸ³é¢‘", expanded=True):
            st.write([f.name for f in uploaded_files if f.name not in st.session_state.processed_files])


# ======== ä¸»å¤„ç†åŒºåŸŸ =========
SEGMENT_DURATION = 5.0  # æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰


if uploaded_files:
    unprocessed = [f for f in uploaded_files if not is_fully_annotated(f)]

    if st.session_state.current_index < len(unprocessed):
        audio_file = unprocessed[st.session_state.current_index]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / SEGMENT_DURATION))

        # åˆå§‹åŒ–éŸ³é¢‘ç‰‡æ®µä¿¡æ¯
        if audio_file.name not in st.session_state.segment_info:
            st.session_state.segment_info[audio_file.name] = {"current_seg": 0, "total_seg": total_segments}
        seg_info = st.session_state.segment_info[audio_file.name]
        seg_idx = seg_info["current_seg"]

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")

        # è®¡ç®—å½“å‰ç‰‡æ®µçš„æ—¶é—´èŒƒå›´
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]

        # ç”Ÿæˆå½“å‰ç‰‡æ®µçš„å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºå›¾è¡¨ç¼“å­˜ï¼‰
        segment_key = f"{audio_file.name}_{seg_idx}_{hashlib.md5(segment_y).hexdigest()}"

        # å¸ƒå±€ï¼šå·¦ä¾§éŸ³é¢‘ä¿¡æ¯ï¼Œå³ä¾§æ ‡ç­¾
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            # æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ
            st.subheader("ğŸ§ æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ")
            audio_bytes = io.BytesIO()
            sf.write(audio_bytes, segment_y, sr, format='WAV')
            st.audio(audio_bytes, format="audio/wav", start_time=0)

            # æ³¢å½¢å›¾å’Œé¢‘è°±å›¾ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤ç”Ÿæˆï¼‰
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
                # æ£€æŸ¥ç¼“å­˜ï¼Œä¸å­˜åœ¨åˆ™ç”Ÿæˆå¹¶ç¼“å­˜
                if f"wave_{segment_key}" not in st.session_state.plot_cache:
                    st.session_state.plot_cache[f"wave_{segment_key}"] = generate_waveform_image(segment_y, sr, segment_key)
                st.image(st.session_state.plot_cache[f"wave_{segment_key}"], caption="Waveform", use_container_width=True)

            with col2:
                st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
                if f"spec_{segment_key}" not in st.session_state.plot_cache:
                    st.session_state.plot_cache[f"spec_{segment_key}"] = generate_spectrogram_image(segment_y, sr, segment_key)
                st.image(st.session_state.plot_cache[f"spec_{segment_key}"], caption="Spectrogram (dB)", use_container_width=True)


        with col_labels:
            st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
            species_list = ["åŒ—æ–¹ç‹­å£è›™", "é»‘æ–‘ä¾§è¤¶è›™", "é‡‘çº¿è›™", "ç‰›è›™", "é¥°çº¹å§¬è›™", "ä¸­åèŸ¾èœ", "æ³½è›™", "å…¶ä»–"]
            current_key_prefix = f"{audio_file.name}_{seg_idx}"

            # é‡ç½®æ ‡ç­¾é€‰æ‹©çŠ¶æ€ï¼ˆä»…å½“åˆ‡æ¢ç‰‡æ®µæ—¶ï¼‰
            if (st.session_state.last_audio_file != audio_file.name or 
                st.session_state.last_seg_idx != seg_idx):
                for label in species_list:
                    st.session_state[f"label_{label}_{current_key_prefix}"] = False
                st.session_state.last_audio_file = audio_file.name
                st.session_state.last_seg_idx = seg_idx

            # æ”¶é›†é€‰ä¸­çš„æ ‡ç­¾
            selected_labels = []
            for label in species_list:
                key = f"label_{label}_{current_key_prefix}"
                if key not in st.session_state:
                    st.session_state[key] = False
                checked = st.checkbox(label, key=key, value=st.session_state[key])
                st.session_state[key] = checked
                if checked:
                    selected_labels.append(label)

            # æ˜¾ç¤ºé€‰ä¸­çŠ¶æ€
            if selected_labels:
                st.success(f"å·²é€‰æ ‡ç­¾: {', '.join(selected_labels)}")
            else:
                st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾")

            # æ“ä½œæŒ‰é’®
            col_save, col_skip = st.columns(2)
            with col_save:
                save_clicked = st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_{current_key_prefix}")
            with col_skip:
                skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_{current_key_prefix}")


        # ä¿å­˜é€»è¾‘
        if save_clicked:
            if not selected_labels:
                st.warning("â—è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾ï¼")
            else:
                # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                segment_filename = f"{os.path.splitext(audio_file.name)[0]}_seg{seg_idx}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜æ ‡æ³¨åˆ°CSV
                entry = {
                    "filename": audio_file.name,
                    "segment_index": segment_filename,
                    "start_time": round(start_sec, 3),
                    "end_time": round(end_sec, 3),
                    "labels": ",".join(selected_labels)
                }
                st.session_state.annotations.append(entry)
                df_combined = pd.concat([df_old, pd.DataFrame([entry])], ignore_index=True)
                df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")

                # åˆ‡æ¢åˆ°ä¸‹ä¸€æ®µæˆ–ä¸‹ä¸€ä¸ªæ–‡ä»¶
                if seg_idx + 1 < total_segments:
                    st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                else:
                    st.session_state.processed_files.add(audio_file.name)
                    st.session_state.current_index += 1

                # æ¸…é™¤å½“å‰ç‰‡æ®µçš„å›¾è¡¨ç¼“å­˜ï¼ˆé¿å…æ®‹ç•™ï¼‰
                if f"wave_{segment_key}" in st.session_state.plot_cache:
                    del st.session_state.plot_cache[f"wave_{segment_key}"]
                if f"spec_{segment_key}" in st.session_state.plot_cache:
                    del st.session_state.plot_cache[f"spec_{segment_key}"]

                st.success("æ ‡æ³¨å·²ä¿å­˜ï¼")
                st.rerun()


        # è·³è¿‡é€»è¾‘
        if skip_clicked:
            if seg_idx + 1 < total_segments:
                st.session_state.segment_info[audio_file.name]["current_seg"] += 1
            else:
                st.session_state.processed_files.add(audio_file.name)
                st.session_state.current_index += 1

            # æ¸…é™¤å½“å‰ç‰‡æ®µçš„å›¾è¡¨ç¼“å­˜
            if f"wave_{segment_key}" in st.session_state.plot_cache:
                del st.session_state.plot_cache[f"wave_{segment_key}"]
            if f"spec_{segment_key}" in st.session_state.plot_cache:
                del st.session_state.plot_cache[f"spec_{segment_key}"]

            st.rerun()


    # æ‰€æœ‰éŸ³é¢‘æ ‡æ³¨å®Œæˆ
    else:
        st.success("ğŸ‰ æ‰€æœ‰ä¸Šä¼ çš„éŸ³é¢‘å·²æ ‡æ³¨å®Œæˆï¼")

else:
    st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)")
