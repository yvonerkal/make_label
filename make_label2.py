import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import zipfile
from io import BytesIO
from PIL import Image
import uuid
from pinyin import pinyin  # ç¡®ä¿å·²å®‰è£…ï¼špip install pinyin


# ======== æ ¸å¿ƒä¼˜åŒ–ï¼šæ‹¼éŸ³é¦–å­—æ¯è½¬æ¢ï¼ˆè§£å†³åŒ¹é…é—®é¢˜ï¼‰ =========
class PinyinHandler:
    @staticmethod
    def get_initial(char):
        """
        èŽ·å–å•ä¸ªå­—ç¬¦çš„æ‹¼éŸ³é¦–å­—æ¯ï¼ˆå¤„ç†å„ç§è¾¹ç¼˜æƒ…å†µï¼‰
        è¿”å›žå€¼ï¼šå°å†™é¦–å­—æ¯ï¼ˆå¦‚"ç‰›"â†’"n"ï¼Œ"W"â†’"w"ï¼Œæœªè¯†åˆ«â†’""ï¼‰
        """
        # å¤„ç†ç©ºå­—ç¬¦æˆ–é•¿å­—ç¬¦ä¸²
        if not char or len(char) != 1:
            return ""
        
        # å¤„ç†å­—æ¯ï¼ˆç›´æŽ¥è¿”å›žå°å†™ï¼‰
        if char.isalpha():
            return char.lower()
        
        # å¤„ç†æ•°å­—å’Œç¬¦å·ï¼ˆç›´æŽ¥è¿”å›žï¼Œä¸å‚ä¸Žé¦–å­—æ¯åŒ¹é…ï¼‰
        if char.isdigit() or char in "._-()[]{}@#$%^&*":
            return ""
        
        # å¤„ç†æ±‰å­—ï¼ˆä½¿ç”¨pinyinåº“ï¼Œå–ç¬¬ä¸€ä¸ªæ‹¼éŸ³çš„é¦–å­—æ¯ï¼‰
        try:
            # pinyin("ç‰›") è¿”å›ž [['niu']] â†’ æå–é¦–å­—æ¯ 'n'
            py_list = pinyin(char)
            if py_list and len(py_list[0]) > 0:
                first_pinyin = py_list[0][0].lower()  # å–ç¬¬ä¸€ä¸ªæ‹¼éŸ³å¹¶å°å†™
                return first_pinyin[0] if first_pinyin else ""  # è¿”å›žé¦–å­—æ¯
            return ""
        except Exception as e:
            # è½¬æ¢å¤±è´¥æ—¶è¿”å›žç©ºï¼ˆé¿å…æŠ¥é”™ï¼‰
            return ""

    @staticmethod
    def label_to_initial(label):
        """å°†æ ‡ç­¾è½¬æ¢ä¸ºæ‹¼éŸ³é¦–å­—æ¯å­—ç¬¦ä¸²ï¼ˆå¦‚"ç‰›è›™_2åž‹"â†’"nw"ï¼‰"""
        return ''.join([PinyinHandler.get_initial(c) for c in label])


# ======== ä¼˜åŒ–ï¼šæ¨¡ç³Šæœç´¢å‡½æ•°ï¼ˆæé«˜åŒ¹é…æˆåŠŸçŽ‡ï¼‰ =========
def fuzzy_search(labels, query):
    """
    å¢žå¼ºç‰ˆæ¨¡ç³Šæœç´¢ï¼Œè§£å†³åŒ¹é…ä¸ä¸Šçš„é—®é¢˜ï¼š
    1. å¿½ç•¥æŸ¥è¯¢ä¸­çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    2. æ”¯æŒé¦–å­—æ¯éƒ¨åˆ†åŒ¹é…ï¼ˆå¦‚"n"åŒ¹é…"ç‰›è›™"ï¼‰
    3. ä¼˜å…ˆè¿”å›žç²¾ç¡®åŒ¹é…ç»“æžœ
    """
    if not query:
        return labels  # ç©ºæŸ¥è¯¢è¿”å›žæ‰€æœ‰æ ‡ç­¾
    
    # é¢„å¤„ç†æŸ¥è¯¢ï¼šåŽ»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œè½¬ä¸ºå°å†™
    query_clean = ''.join([c.lower() for c in query if c.isalnum()])
    if not query_clean:
        return labels
    
    matched = []
    for label in labels:
        label_clean = label.lower()
        label_initial = PinyinHandler.label_to_initial(label)  # æ ‡ç­¾é¦–å­—æ¯ä¸²
        
        # è§„åˆ™1ï¼šæ ‡ç­¾åŒ…å«æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆåŽŸå§‹å­—ç¬¦åŒ¹é…ï¼‰
        if query_clean in label_clean:
            matched.append((label, 3))  # ä¼˜å…ˆçº§3ï¼ˆæœ€é«˜ï¼‰
            continue
        
        # è§„åˆ™2ï¼šæ ‡ç­¾é¦–å­—æ¯åŒ…å«æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆé¦–å­—æ¯åŒ¹é…ï¼‰
        if query_clean in label_initial:
            matched.append((label, 2))  # ä¼˜å…ˆçº§2
            continue
        
        # è§„åˆ™3ï¼šæŸ¥è¯¢æ˜¯æ ‡ç­¾é¦–å­—æ¯çš„å­åºåˆ—ï¼ˆå¦‚"nw"åŒ¹é…"nww"ï¼‰
        it = iter(label_initial)
        if all(c in it for c in query_clean):
            matched.append((label, 1))  # ä¼˜å…ˆçº§1
            continue
    
    # æŒ‰ä¼˜å…ˆçº§æŽ’åºï¼ˆç²¾ç¡®åŒ¹é…åœ¨å‰ï¼‰ï¼ŒåŽ»é‡åŽè¿”å›ž
    if matched:
        # åŽ»é‡å¹¶æŒ‰ä¼˜å…ˆçº§æŽ’åº
        unique_matched = list({label: prio for label, prio in matched}.items())
        unique_matched.sort(key=lambda x: -x[1])  # ä¼˜å…ˆçº§é«˜çš„æŽ’å‰é¢
        return [item[0] for item in unique_matched]
    return []  # æ— åŒ¹é…æ—¶è¿”å›žç©ºåˆ—è¡¨


# ======== å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ =========
@st.cache_data(show_spinner=False)
def load_audio(file):
    return librosa.load(file, sr=None)


@st.cache_data(show_spinner=False)
def generate_spectrogram_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


@st.cache_data(show_spinner=False)
def generate_waveform_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = []
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()
if "audio_state" not in st.session_state:
    st.session_state.audio_state = {
        "processed_files": set(),
        "current_index": 0,
        "segment_info": {},
        "last_audio_file": None,
        "last_seg_idx": -1,
        "annotations": []
    }
if "filtered_labels_cache" not in st.session_state:
    st.session_state.filtered_labels_cache = {}

st.set_page_config(layout="wide")
st.title("ðŸ¸ é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·ï¼ˆæ‹¼éŸ³åŒ¹é…ä¼˜åŒ–ç‰ˆï¼‰")


# ======== æ ‡ç­¾ç®¡ç†ç»„ä»¶ =========
def label_management_component():
    with st.sidebar:
        st.markdown("### ðŸ·ï¸ æ ‡ç­¾è®¾ç½®")
        with st.form("label_form", clear_on_submit=True):
            label_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", type=["txt"], key="label_file")
            submit_label = st.form_submit_button("åŠ è½½æ ‡ç­¾")
            if submit_label and label_file:
                try:
                    species_list = [line.strip() for line in label_file.read().decode("utf-8").split("\n") if line.strip()]
                    if species_list:
                        st.session_state["dynamic_species_list"] = species_list
                        st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(species_list)} ä¸ªæ ‡ç­¾")
                        st.rerun()
                    else:
                        st.error("æ ‡ç­¾æ–‡ä»¶ä¸ºç©º")
                except Exception as e:
                    st.error(f"é”™è¯¯ï¼š{str(e)}")
        st.info("âœ… å·²å¯ç”¨æ‹¼éŸ³é¦–å­—æ¯æœç´¢ï¼ˆæ”¯æŒæ±‰å­—ã€å­—æ¯æ··åˆæŸ¥è¯¢ï¼‰")
        st.markdown("#### å½“å‰æ ‡ç­¾é¢„è§ˆ")
        st.write(st.session_state["dynamic_species_list"][:5] + (["..."] if len(st.session_state["dynamic_species_list"]) > 5 else []))
    return st.session_state["dynamic_species_list"]


# ======== å³ä¾§æ ‡æ³¨æ ‡ç­¾ç»„ä»¶ï¼ˆæ˜¾ç¤ºåŒ¹é…ç»†èŠ‚ï¼‰ =========
def annotation_labels_component(current_segment_key):
    species_list = st.session_state["dynamic_species_list"]
    col_labels = st.container()

    with col_labels:
        st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
        if not species_list:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶")
            return None, None

        # æœç´¢æ¡†ï¼ˆæç¤ºä½¿ç”¨æ–¹æ³•ï¼‰
        search_query = st.text_input(
            "ðŸ” æœç´¢æ ‡ç­¾ï¼ˆç¤ºä¾‹ï¼šè¾“å…¥'nw'æ‰¾'ç‰›è›™'ï¼Œè¾“å…¥'ç‰›'ä¹Ÿå¯ï¼‰",
            "",
            key=f"search_{current_segment_key}"
        )

        # ç¼“å­˜æœç´¢ç»“æžœï¼ˆæé«˜æ€§èƒ½ï¼‰
        cache_key = f"{current_segment_key}_{search_query}"
        if cache_key not in st.session_state.filtered_labels_cache:
            st.session_state.filtered_labels_cache[cache_key] = fuzzy_search(
                species_list,
                search_query
            )
        filtered_species = st.session_state.filtered_labels_cache[cache_key]

        # æ˜¾ç¤ºåŒ¹é…ä¿¡æ¯ï¼ˆå¸®åŠ©ç”¨æˆ·ç†è§£ç»“æžœï¼‰
        st.info(
            f"æ‰¾åˆ° {len(filtered_species)} ä¸ªåŒ¹é…æ ‡ç­¾ "
            f"ï¼ˆæ€»æ ‡ç­¾æ•°ï¼š{len(species_list)}ï¼‰"
        )

        # æ˜¾ç¤ºæ ‡ç­¾åŠé¦–å­—æ¯ï¼ˆæ–¹ä¾¿ç”¨æˆ·æ ¸å¯¹ï¼‰
        with st.container(height=300):  # å›ºå®šé«˜åº¦+æ»šåŠ¨æ¡
            for label in filtered_species:
                label_initial = PinyinHandler.label_to_initial(label)
                # æ˜¾ç¤ºæ ‡ç­¾å’Œå…¶é¦–å­—æ¯ï¼ˆå¦‚"ç‰›è›™ï¼ˆé¦–å­—æ¯ï¼šnwï¼‰"ï¼‰
                display_text = f"{label}ï¼ˆé¦–å­—æ¯ï¼š{label_initial}ï¼‰" if label_initial else label
                
                key = f"label_{label}_{current_segment_key}"
                is_selected = label in st.session_state.current_selected_labels
                if st.checkbox(display_text, key=key, value=is_selected):
                    st.session_state.current_selected_labels.add(label)
                else:
                    st.session_state.current_selected_labels.discard(label)

        # å·²é€‰æ ‡ç­¾å±•ç¤º
        st.markdown("### å·²é€‰æ ‡ç­¾")
        st.info(f"å·²é€‰æ•°é‡ï¼š{len(st.session_state.current_selected_labels)}")
        if st.session_state.current_selected_labels:
            st.success("æ ‡ç­¾ï¼š\n" + ", ".join(st.session_state.current_selected_labels).replace(", ", "\n"))
        else:
            st.info("å°šæœªé€‰æ‹©æ ‡ç­¾")

        st.markdown("### ðŸ› ï¸ æ“ä½œ")
        col_save, col_skip = st.columns(2)
        return col_save, col_skip


# ======== éŸ³é¢‘å¤„ç†é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰ =========
def process_audio():
    audio_state = st.session_state.audio_state
    output_dir = "uploaded_audios"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")

    try:
        df_old = pd.read_csv(csv_path) if os.path.exists(csv_path) else pd.DataFrame(
            columns=["filename", "segment_index", "start_time", "end_time", "labels"]
        )
    except:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])

    with st.sidebar:
        st.markdown("### ðŸŽµ éŸ³é¢‘ä¸Šä¼ ")
        uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True, key="audio_files")
        st.markdown("### ðŸ“¥ ä¸‹è½½ç»“æžœ")
        if os.path.exists(csv_path):
            with open(csv_path, "rb") as f:
                st.download_button("ðŸ“„ ä¸‹è½½CSV", f, "annotations.csv", "text/csv")
        annotated_paths = []
        if os.path.exists(csv_path) and "segment_index" in pd.read_csv(csv_path).columns:
            for _, row in pd.read_csv(csv_path).iterrows():
                try:
                    fname = str(row["segment_index"])
                    if fname and os.path.exists(os.path.join(output_dir, fname)):
                        annotated_paths.append(os.path.join(output_dir, fname))
                except:
                    pass
        if annotated_paths:
            with zipfile.ZipFile(zip_buf := BytesIO(), "w") as zf:
                for p in annotated_paths:
                    zf.write(p, os.path.basename(p))
            zip_buf.seek(0)
            st.download_button("ðŸŽµ ä¸‹è½½éŸ³é¢‘ç‰‡æ®µ", zip_buf, "annotated_segments.zip", "application/zip")

    if not uploaded_files:
        st.info("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        return

    unprocessed = [f for f in uploaded_files if not (audio_state["segment_info"].get(f.name) and
                                                     audio_state["segment_info"][f.name]["current_seg"] >=
                                                     audio_state["segment_info"][f.name]["total_seg"])]

    if audio_state["current_index"] < len(unprocessed):
        audio_file = unprocessed[audio_state["current_index"]]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / 5.0))
        seg_idx = audio_state["segment_info"].get(audio_file.name, {"current_seg": 0})["current_seg"]
        current_segment_key = f"{audio_file.name}_{seg_idx}"

        if (audio_state["last_audio_file"] != audio_file.name or audio_state["last_seg_idx"] != seg_idx):
            st.session_state.current_selected_labels = set()
            audio_state["last_audio_file"], audio_state["last_seg_idx"] = audio_file.name, seg_idx

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            st.subheader("ðŸŽ§ æ’­æ”¾å½“å‰ç‰‡æ®µ")
            start_sec, end_sec = seg_idx * 5.0, min((seg_idx + 1) * 5.0, total_duration)
            segment_y = y[int(start_sec * sr):int(end_sec * sr)]
            audio_bytes = BytesIO()
            sf.write(audio_bytes, segment_y, sr, format='WAV')
            st.audio(audio_bytes, format="audio/wav")

            col1, col2 = st.columns(2)
            with col1:
                st.image(generate_waveform_image(segment_y, sr), caption="æ³¢å½¢å›¾", use_container_width=True)
            with col2:
                st.image(generate_spectrogram_image(segment_y, sr), caption="é¢‘è°±å›¾", use_container_width=True)

        with col_labels:
            col_save, col_skip = annotation_labels_component(current_segment_key)

            if col_save and col_skip:
                with col_save:
                    if st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_{current_segment_key}"):
                        try:
                            if not st.session_state.current_selected_labels:
                                st.warning("â—è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾")
                                return

                            os.makedirs(output_dir, exist_ok=True)
                            base_name = os.path.splitext(audio_file.name)[0]
                            unique_id = uuid.uuid4().hex[:8]
                            segment_filename = f"{base_name}_seg{seg_idx}_{unique_id}.wav"
                            segment_path = os.path.join(output_dir, segment_filename)

                            try:
                                with sf.SoundFile(segment_path, 'w', samplerate=sr, channels=1) as f:
                                    f.write(segment_y)
                            except Exception as audio_error:
                                st.error(f"éŸ³é¢‘ä¿å­˜å¤±è´¥: {str(audio_error)}")
                                return

                            clean_labels = [label.replace("/", "").replace("\\", "") for label in
                                            st.session_state.current_selected_labels]
                            entry = {
                                "filename": audio_file.name,
                                "segment_index": segment_filename,
                                "start_time": round(start_sec, 3),
                                "end_time": round(end_sec, 3),
                                "labels": ",".join(clean_labels)
                            }

                            try:
                                new_df = pd.DataFrame([entry])
                                if os.path.exists(csv_path):
                                    existing_df = pd.read_csv(csv_path)
                                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                                else:
                                    combined_df = new_df

                                combined_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                            except Exception as csv_error:
                                st.error(f"CSVä¿å­˜å¤±è´¥: {str(csv_error)}")
                                if os.path.exists(segment_path):
                                    os.remove(segment_path)
                                return

                            if audio_file.name not in audio_state["segment_info"]:
                                audio_state["segment_info"][audio_file.name] = {
                                    "current_seg": 0,
                                    "total_seg": total_segments
                                }

                            if seg_idx + 1 < total_segments:
                                audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                            else:
                                audio_state["processed_files"].add(audio_file.name)
                                audio_state["current_index"] += 1

                            st.session_state.audio_state = audio_state
                            st.success(f"æˆåŠŸä¿å­˜æ ‡æ³¨ï¼æ–‡ä»¶: {segment_filename}")
                            st.balloons()
                            st.rerun()

                        except Exception as e:
                            st.error(f"ä¿å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

                with col_skip:
                    if st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_{current_segment_key}"):
                        if seg_idx + 1 < total_segments:
                            audio_state["segment_info"][audio_file.name]["current_seg"] += 1
                        else:
                            audio_state["processed_files"].add(audio_file.name)
                            audio_state["current_index"] += 1
                        st.rerun()

    else:
        st.success("ðŸŽ‰ æ‰€æœ‰éŸ³é¢‘æ ‡æ³¨å®Œæˆï¼")

    st.session_state.audio_state = audio_state


# ======== ä¸»æµç¨‹ =========
if __name__ == "__main__":
    label_management_component()
    process_audio()
