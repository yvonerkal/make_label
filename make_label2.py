import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import uuid
from PIL import Image
import zipfile
from io import BytesIO

# éŸ³é¢‘é¢„åŠ è½½å’Œè‡ªåŠ¨æ’­æ”¾åŠŸèƒ½
# ======== å·¥å…·å‡½æ•° =========
@st.cache_data
def load_audio(file):
    return librosa.load(file, sr=None)

@st.cache_data
def generate_spectrogram_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)

@st.cache_data
def generate_waveform_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)

def is_fully_annotated(file):
    info = st.session_state.segment_info.get(file.name)
    if info is None:
        return False
    return info["current_seg"] >= info["total_seg"]

# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "segment_info" not in st.session_state:
    st.session_state.segment_info = {}
if "last_audio_file" not in st.session_state:
    st.session_state.last_audio_file = None
if "last_seg_idx" not in st.session_state:
    st.session_state.last_seg_idx = -1
if "auto_play" not in st.session_state:
    st.session_state.auto_play = True  # è‡ªåŠ¨æ’­æ”¾å¼€å…³
if "audio_context" not in st.session_state:
    st.session_state.audio_context = None  # éŸ³é¢‘ä¸Šä¸‹æ–‡
if "audio_unlocked" not in st.session_state:
    st.session_state.audio_unlocked = False  # éŸ³é¢‘æ˜¯å¦è§£é”ï¼ˆç”¨æˆ·å·²äº¤äº’ï¼‰
if "preloaded_audios" not in st.session_state:
    st.session_state.preloaded_audios = {}  # é¢„åŠ è½½çš„éŸ³é¢‘

st.set_page_config(layout="wide")

st.title("ğŸ¸ é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")

# ======== ä¾§è¾¹æ  =========
with st.sidebar:
    uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True)
    output_dir = st.text_input("ä¿å­˜ç›®å½•", "E:/Frog audio classification/uploaded_audios")
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")
    if os.path.exists(csv_path):
        df_old = pd.read_csv(csv_path, encoding="utf-8")
    else:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])

    # ä¸‹è½½åŒºåŸŸ
    st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡æ³¨ç»“æœ")
    if os.path.exists(csv_path):
        with open(csv_path, "rb") as f:
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ ‡æ³¨CSVæ–‡ä»¶",
                data=f,
                file_name="annotations.csv",
                mime="text/csv"
            )

    # éŸ³é¢‘ç‰‡æ®µä¸‹è½½
    annotated_paths = []
    if os.path.exists(csv_path):
        df_tmp = pd.read_csv(csv_path)
        for fname in df_tmp["segment_index"]:
            full_path = os.path.join(output_dir, fname)
            if os.path.exists(full_path):
                annotated_paths.append(full_path)

    if annotated_paths:
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zip_file:
            for path in annotated_paths:
                arcname = os.path.basename(path)
                zip_file.write(path, arcname=arcname)
        zip_buffer.seek(0)
        st.download_button(
            label="ğŸµ ä¸‹è½½æ ‡æ³¨éŸ³é¢‘ (ZIP)",
            data=zip_buffer,
            file_name="annotated_audio_segments.zip",
            mime="application/zip"
        )

    # è‡ªåŠ¨æ’­æ”¾å¼€å…³
    st.session_state.auto_play = st.checkbox("è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘", value=st.session_state.auto_play)

    # æ ‡æ³¨çŠ¶æ€æ˜¾ç¤º
    if uploaded_files:
        with st.expander("âœ… å·²æ ‡æ³¨éŸ³é¢‘", expanded=True):
            for f in uploaded_files:
                if f.name in st.session_state.processed_files:
                    st.write(f.name)
        with st.expander("ğŸ•“ æœªæ ‡æ³¨éŸ³é¢‘", expanded=True):
            st.write([f.name for f in uploaded_files if f.name not in st.session_state.processed_files])

# ======== ä¸»å¤„ç†åŒºåŸŸ =========
SEGMENT_DURATION = 5.0  # æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰

# éŸ³é¢‘è§£é”å‡½æ•° - é¦–æ¬¡ç”¨æˆ·äº¤äº’æ—¶è°ƒç”¨
def unlock_audio():
    if not st.session_state.audio_unlocked:
        st.session_state.audio_unlocked = True
        st.info("ğŸ”Š éŸ³é¢‘å·²è§£é”ï¼Œç°åœ¨å¯ä»¥è‡ªåŠ¨æ’­æ”¾")
        st.experimental_rerun()

# é¢„åŠ è½½å½“å‰å’Œä¸‹ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µ
def preload_audio(audio_file, seg_idx):
    key = f"{audio_file.name}_{seg_idx}"
    if key not in st.session_state.preloaded_audios:
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        
        # è®¡ç®—å½“å‰æ®µè½çš„æ—¶é—´èŒƒå›´
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]
        
        # ç”ŸæˆéŸ³é¢‘æ•°æ®
        audio_bytes = io.BytesIO()
        sf.write(audio_bytes, segment_y, sr, format='WAV')
        audio_data = audio_bytes.getvalue()
        
        st.session_state.preloaded_audios[key] = {
            'data': audio_data,
            'sr': sr
        }
        
        # é¢„åŠ è½½ä¸‹ä¸€ä¸ªç‰‡æ®µ
        next_seg_idx = seg_idx + 1
        next_key = f"{audio_file.name}_{next_seg_idx}"
        if next_seg_idx < int(np.ceil(total_duration / SEGMENT_DURATION)) and next_key not in st.session_state.preloaded_audios:
            next_start_sec = next_seg_idx * SEGMENT_DURATION
            next_end_sec = min((next_seg_idx + 1) * SEGMENT_DURATION, total_duration)
            next_start_sample = int(next_start_sec * sr)
            next_end_sample = int(next_end_sec * sr)
            next_segment_y = y[next_start_sample:next_end_sample]
            
            next_audio_bytes = io.BytesIO()
            sf.write(next_audio_bytes, next_segment_y, sr, format='WAV')
            next_audio_data = next_audio_bytes.getvalue()
            
            st.session_state.preloaded_audios[next_key] = {
                'data': next_audio_data,
                'sr': sr
            }

if uploaded_files:
    unprocessed = [f for f in uploaded_files if not is_fully_annotated(f)]

    if st.session_state.current_index < len(unprocessed):
        audio_file = unprocessed[st.session_state.current_index]
        y, sr = load_audio(audio_file)
        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / SEGMENT_DURATION))

        if audio_file.name not in st.session_state.segment_info:
            st.session_state.segment_info[audio_file.name] = {"current_seg": 0, "total_seg": total_segments}

        seg_info = st.session_state.segment_info[audio_file.name]
        seg_idx = seg_info["current_seg"]

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")

        # é¢„åŠ è½½å½“å‰å’Œä¸‹ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µ
        preload_audio(audio_file, seg_idx)

        # è®¡ç®—å½“å‰æ®µè½çš„æ—¶é—´èŒƒå›´
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]

        # å¸ƒå±€è°ƒæ•´ï¼šå·¦ä¾§éŸ³é¢‘ä¿¡æ¯ï¼Œå³ä¾§æ ‡ç­¾å’Œæ“ä½œ
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            # æ’­æ”¾éŸ³é¢‘æ®µ
            st.subheader("ğŸ§ æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ")
            
            # è·å–é¢„åŠ è½½çš„éŸ³é¢‘æ•°æ®
            key = f"{audio_file.name}_{seg_idx}"
            audio_data = st.session_state.preloaded_audios[key]['data']
            sr = st.session_state.preloaded_audios[key]['sr']
            
            # ç”ŸæˆéšæœºIDï¼Œç¡®ä¿æ¯æ¬¡åŠ è½½æ–°éŸ³é¢‘æ—¶IDä¸åŒ
            audio_id = f"audio_{uuid.uuid4()}"
            
            # éŸ³é¢‘è§£é”æŒ‰é’®ï¼ˆä»…åœ¨æœªè§£é”æ—¶æ˜¾ç¤ºï¼‰
            if not st.session_state.audio_unlocked:
                st.warning("""
                ğŸ”‡ ä¸ºäº†å¯ç”¨è‡ªåŠ¨æ’­æ”¾åŠŸèƒ½ï¼Œè¯·å…ˆç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è§£é”éŸ³é¢‘ã€‚
                è¿™æ˜¯æµè§ˆå™¨çš„å®‰å…¨é™åˆ¶ï¼Œåªéœ€è¦ç‚¹å‡»ä¸€æ¬¡å³å¯ã€‚
                """)
                if st.button("è§£é”éŸ³é¢‘æ’­æ”¾", key="unlock_button"):
                    unlock_audio()
            
            # ä½¿ç”¨HTMLéŸ³é¢‘å…ƒç´ 
            if st.session_state.audio_unlocked and st.session_state.auto_play:
                # å·²è§£é”ä¸”å¯ç”¨è‡ªåŠ¨æ’­æ”¾
                st.markdown(f"""
                <audio id="{audio_id}" autoplay controls>
                    <source src="data:audio/wav;base64,{audio_data.hex()}" type="audio/wav">
                    æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚
                </audio>
                <script>
                    // éŸ³é¢‘è‡ªåŠ¨æ’­æ”¾é€»è¾‘
                    var audio = document.getElementById('{audio_id}');
                    audio.play().catch(e => {{
                        console.log('è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢:', e);
                    }});
                </script>
                """, unsafe_allow_html=True)
                st.info("âœ… è‡ªåŠ¨æ’­æ”¾å·²å¯ç”¨")
            else:
                # æœªè§£é”æˆ–ç¦ç”¨è‡ªåŠ¨æ’­æ”¾
                st.audio(audio_data, format="audio/wav", start_time=0)
                if st.session_state.audio_unlocked:
                    st.info("ğŸ”‡ è‡ªåŠ¨æ’­æ”¾å·²ç¦ç”¨ï¼Œç‚¹å‡»æ’­æ”¾æŒ‰é’®æ‰‹åŠ¨æ’­æ”¾éŸ³é¢‘")
                else:
                    st.info("ğŸ”’ éŸ³é¢‘å·²é”å®šï¼Œè¯·å…ˆè§£é”ä»¥å¯ç”¨è‡ªåŠ¨æ’­æ”¾")

            # æ³¢å½¢å›¾ + é¢‘è°±å›¾
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
                wave_img = generate_waveform_image(segment_y, sr)
                st.image(wave_img, caption="Waveform", use_container_width=True)

            with col2:
                st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
                spec_img = generate_spectrogram_image(segment_y, sr)
                st.image(spec_img, caption="Spectrogram (dB)", use_container_width=True)

        with col_labels:  # å³ä¾§åŒºåŸŸï¼šæ ‡ç­¾é€‰æ‹© + æ“ä½œæŒ‰é’®
            st.markdown("### ğŸ¸ ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
            species_list = ["Rana", "Hyla", "Bufo", "Fejervarya", "Microhyla", "Other"]
            current_key_prefix = f"{audio_file.name}_{seg_idx}"

            # åˆ‡æ¢ç‰‡æ®µæ—¶é‡ç½®å¤é€‰æ¡†çŠ¶æ€
            if (st.session_state.last_audio_file != audio_file.name
                    or st.session_state.last_seg_idx != seg_idx):
                for label in species_list:
                    key = f"label_checkbox_{label}_{current_key_prefix}"
                    st.session_state[key] = False
                st.session_state.last_audio_file = audio_file.name
                st.session_state.last_seg_idx = seg_idx

            # æ¸²æŸ“å¤é€‰æ¡†å¹¶æ”¶é›†é€‰ä¸­çš„æ ‡ç­¾
            selected_labels = []
            for label in species_list:
                key = f"label_checkbox_{label}_{current_key_prefix}"
                if key not in st.session_state:
                    st.session_state[key] = False
                checked = st.checkbox(label, key=key, value=st.session_state[key])
                if checked != st.session_state[key]:
                    st.session_state[key] = checked
                if st.session_state[key]:
                    selected_labels.append(label)

            # æ˜¾ç¤ºå·²é€‰æ ‡ç­¾
            if selected_labels:
                st.success(f"å·²é€‰æ ‡ç­¾: {', '.join(selected_labels)}")
            else:
                st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾")

            # æ“ä½œæŒ‰é’®
            st.markdown("### ğŸ› ï¸ æ“ä½œ")
            col_save, col_skip = st.columns(2)
            with col_save:
                save_clicked = st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_btn_{current_key_prefix}")
            with col_skip:
                skip_clicked = st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_btn_{current_key_prefix}")

        # ä¿å­˜é€»è¾‘
        if save_clicked:
            if not selected_labels:
                st.warning("â—è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰©ç§æ ‡ç­¾ï¼")
            else:
                # ä¿å­˜åˆ†ç‰‡éŸ³é¢‘
                segment_filename = f"{os.path.splitext(audio_file.name)[0]}_seg{seg_idx}.wav"
                segment_path = os.path.join(output_dir, segment_filename)
                sf.write(segment_path, segment_y, sr)

                # ä¿å­˜åˆ°CSV
                entry = {
                    "filename": audio_file.name,
                    "segment_index": segment_filename,
                    "start_time": round(start_sec, 3),
                    "end_time": round(end_sec, 3),
                    "labels": ",".join(selected_labels)
                }

                st.session_state.annotations.append(entry)
                df_combined = pd.concat([df_old, pd.DataFrame([entry])], ignore_index=True)
                df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")

                # åˆ‡æ¢åˆ†ç‰‡æˆ–ä¸‹ä¸€ä¸ªæ–‡ä»¶
                if seg_idx + 1 < total_segments:
                    st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                else:
                    st.session_state.processed_files.add(audio_file.name)
                    st.session_state.current_index += 1

                st.success("æ ‡æ³¨å·²ä¿å­˜ï¼")
                st.experimental_rerun()

        if skip_clicked:
            if seg_idx + 1 < total_segments:
                st.session_state.segment_info[audio_file.name]["current_seg"] += 1
            else:
                st.session_state.processed_files.add(audio_file.name)
                st.session_state.current_index += 1
            st.experimental_rerun()

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆ
    all_done = True
    for f in uploaded_files:
        info = st.session_state.segment_info.get(f.name)
        if info is None or info["current_seg"] < info["total_seg"]:
            all_done = False
            break
    if all_done:
        st.success("ğŸ‰ æ‰€æœ‰ä¸Šä¼ çš„éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆï¼")

else:
    st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è‡³å°‘ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")
