import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import pandas as pd
import os
import io
import zipfile
from io import BytesIO


# ======== å·¥å…·å‡½æ•° =========
@st.cache_data  # ç¼“å­˜éŸ³é¢‘åŠ è½½ç»“æœï¼Œé¿å…é‡è¿è¡Œæ—¶é‡å¤åŠ è½½
def load_audio(file):
    return librosa.load(file, sr=None)


@st.cache_data  # ç¼“å­˜å›¾è¡¨ç”Ÿæˆç»“æœ
def generate_spectrogram_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)
    ax.set(title="Spectrogram (dB)")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


@st.cache_data  # ç¼“å­˜å›¾è¡¨ç”Ÿæˆç»“æœ
def generate_waveform_image(y, sr):
    fig, ax = plt.subplots(figsize=(5, 3))
    librosa.display.waveshow(y, sr=sr)
    ax.set(title="Waveform")
    fig.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return Image.open(buf)


def is_fully_annotated(file):
    info = st.session_state.segment_info.get(file.name)
    if info is None:
        return False
    return info["current_seg"] >= info["total_seg"]


# ======== Session çŠ¶æ€åˆå§‹åŒ– =========
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "segment_info" not in st.session_state:
    st.session_state.segment_info = {}
if "last_audio_file" not in st.session_state:
    st.session_state.last_audio_file = None
if "last_seg_idx" not in st.session_state:
    st.session_state.last_seg_idx = -1
if "dynamic_species_list" not in st.session_state:
    st.session_state["dynamic_species_list"] = [
        "åŒ—æ–¹ç‹­å£è›™", "é»‘æ–‘ä¾§è¤¶è›™", "é‡‘çº¿è›™", "ç‰›è›™", "é¥°çº¹å§¬è›™", "ä¸­åèŸ¾èœ", "æ³½è›™", "å…¶ä»–"
    ]
if "current_selected_labels" not in st.session_state:
    st.session_state.current_selected_labels = set()
# æ–°å¢ï¼šæ ‡è®°æ˜¯å¦éœ€è¦æ›´æ–°æ ‡ç­¾ï¼Œé¿å…å…¨é¡µé¢é‡è¿è¡Œ
if "needs_label_update" not in st.session_state:
    st.session_state.needs_label_update = False


st.set_page_config(layout="wide")
st.title("é’è›™éŸ³é¢‘æ ‡æ³¨å·¥å…·")


# ======== æ ‡ç­¾æ›´æ–°å‡½æ•°ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰ =========
def update_labels(label_file):
    """å¤„ç†æ ‡ç­¾æ–‡ä»¶å¹¶æ›´æ–°ï¼Œä¸è§¦å‘å…¨é¡µé¢é‡è¿è¡Œ"""
    try:
        content = label_file.read().decode("utf-8")
        species_list = [line.strip() for line in content.split("\n") if line.strip()]
        if species_list:
            st.session_state["dynamic_species_list"] = species_list
            st.session_state.needs_label_update = True  # æ ‡è®°éœ€è¦æ›´æ–°æ ‡ç­¾æ˜¾ç¤º
            return True, f"æˆåŠŸåŠ è½½ {len(species_list)} ä¸ªæ ‡ç­¾ï¼"
        else:
            return False, "æ ‡ç­¾æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å†…å®¹"
    except UnicodeDecodeError:
        return False, "æ ‡ç­¾æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨UTF-8"
    except Exception as e:
        return False, f"è¯»å–å¤±è´¥ï¼š{str(e)}"


# ======== ä¾§è¾¹æ  =========
with st.sidebar:
    uploaded_files = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (.wav)", type=["wav"], accept_multiple_files=True)
    output_dir = "E:/Frog audio classification/uploaded_audios"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "annotations.csv")
    if os.path.exists(csv_path):
        df_old = pd.read_csv(csv_path, encoding="utf-8")
    else:
        df_old = pd.DataFrame(columns=["filename", "segment_index", "start_time", "end_time", "labels"])

    # æ ‡ç­¾è®¾ç½®ï¼ˆä¼˜åŒ–åï¼‰
    st.markdown("### ğŸ·ï¸ æ ‡ç­¾è®¾ç½®")
    # ä½¿ç”¨å›è°ƒå‡½æ•°å¤„ç†æ ‡ç­¾ä¸Šä¼ ï¼Œé¿å…ç«‹å³é‡è¿è¡Œ
    label_file = st.file_uploader(
        "ä¸Šä¼ æ ‡ç­¾æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼‰", 
        type=["txt"], 
        key="label_file_uploader",
        on_change=lambda: update_labels(label_file) if label_file else None
    )

    # æ˜¾ç¤ºæ ‡ç­¾æ›´æ–°ç»“æœï¼ˆå³æ—¶åé¦ˆï¼‰
    if label_file:
        success, msg = update_labels(label_file)
        if success:
            st.success(msg)
        else:
            st.error(msg)

    st.markdown("#### å½“å‰æ ‡ç­¾åˆ—è¡¨")
    st.write(st.session_state["dynamic_species_list"])

    # ä¸‹è½½åŒºåŸŸ
    st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡æ³¨ç»“æœ")
    if os.path.exists(csv_path):
        with open(csv_path, "rb") as f:
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æ ‡æ³¨CSVæ–‡ä»¶",
                data=f,
                file_name="annotations.csv",
                mime="text/csv"
            )

    # éŸ³é¢‘ç‰‡æ®µä¸‹è½½
    annotated_paths = []
    if os.path.exists(csv_path) and "segment_index" in pd.read_csv(csv_path).columns:
        df_tmp = pd.read_csv(csv_path)
        for idx, row in df_tmp.iterrows():
            try:
                fname = str(row["segment_index"])
                if pd.notna(fname) and fname.strip():
                    full_path = os.path.join(output_dir, fname)
                    if os.path.exists(full_path):
                        annotated_paths.append(full_path)
            except Exception as e:
                st.warning(f"å¤„ç†è·¯å¾„æ—¶å‡ºé”™: {str(e)}")

    if annotated_paths:
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zip_file:
            for path in annotated_paths:
                zip_file.write(path, os.path.basename(path))
        zip_buffer.seek(0)
        st.download_button(
            label="ğŸµ ä¸‹è½½æ ‡æ³¨éŸ³é¢‘ (ZIP)",
            data=zip_buffer,
            file_name="annotated_audio_segments.zip",
            mime="application/zip"
        )


# ======== ä¸»å¤„ç†åŒºåŸŸ =========
SEGMENT_DURATION = 5.0  # æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰


if uploaded_files:
    unprocessed = [f for f in uploaded_files if not is_fully_annotated(f)]

    if st.session_state.current_index < len(unprocessed):
        audio_file = unprocessed[st.session_state.current_index]
        # ä»…åœ¨é¦–æ¬¡åŠ è½½æˆ–éŸ³é¢‘æ–‡ä»¶å˜åŒ–æ—¶æ‰é‡æ–°åŠ è½½ï¼ˆåˆ©ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—ï¼‰
        if (st.session_state.last_audio_file != audio_file.name or 
            f"audio_{audio_file.name}" not in st.session_state):
            y, sr = load_audio(audio_file)
            st.session_state[f"audio_{audio_file.name}"] = (y, sr)  # ç¼“å­˜éŸ³é¢‘æ•°æ®
        else:
            y, sr = st.session_state[f"audio_{audio_file.name}"]  # ç›´æ¥ä½¿ç”¨ç¼“å­˜

        total_duration = librosa.get_duration(y=y, sr=sr)
        total_segments = int(np.ceil(total_duration / SEGMENT_DURATION))

        if audio_file.name not in st.session_state.segment_info:
            st.session_state.segment_info[audio_file.name] = {"current_seg": 0, "total_seg": total_segments}
        seg_info = st.session_state.segment_info[audio_file.name]
        seg_idx = seg_info["current_seg"]

        # åˆ‡æ¢ç‰‡æ®µæ—¶é‡ç½®é€‰ä¸­æ ‡ç­¾
        current_segment_key = f"{audio_file.name}_{seg_idx}"
        if (st.session_state.last_audio_file != audio_file.name
                or st.session_state.last_seg_idx != seg_idx):
            st.session_state.current_selected_labels = set()
            st.session_state.last_audio_file = audio_file.name
            st.session_state.last_seg_idx = seg_idx

        st.header(f"æ ‡æ³¨éŸ³é¢‘: {audio_file.name} - ç¬¬ {seg_idx + 1}/{total_segments} æ®µ")

        # è®¡ç®—å½“å‰ç‰‡æ®µçš„æ—¶é—´èŒƒå›´
        start_sec = seg_idx * SEGMENT_DURATION
        end_sec = min((seg_idx + 1) * SEGMENT_DURATION, total_duration)
        start_sample = int(start_sec * sr)
        end_sample = int(end_sec * sr)
        segment_y = y[start_sample:end_sample]

        # å¸ƒå±€ï¼šå·¦ä¾§éŸ³é¢‘ä¿¡æ¯ï¼Œå³ä¾§æ ‡ç­¾
        col_main, col_labels = st.columns([3, 1])

        with col_main:
            st.subheader("ğŸ§ æ’­æ”¾å½“å‰éŸ³é¢‘ç‰‡æ®µ")
            audio_bytes = io.BytesIO()
            sf.write(audio_bytes, segment_y, sr, format='WAV')
            st.audio(audio_bytes, format="audio/wav", start_time=0)

            # æ³¢å½¢å›¾å’Œé¢‘è°±å›¾ï¼ˆä½¿ç”¨ç¼“å­˜å‡å°‘é‡ç»˜æ—¶é—´ï¼‰
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“ˆ æ³¢å½¢å›¾")
                if f"wave_{current_segment_key}" not in st.session_state:
                    st.session_state[f"wave_{current_segment_key}"] = generate_waveform_image(segment_y, sr)
                st.image(st.session_state[f"wave_{current_segment_key}"], caption="Waveform", use_container_width=True)
            with col2:
                st.markdown("#### ğŸï¸ é¢‘è°±å›¾")
                if f"spec_{current_segment_key}" not in st.session_state:
                    st.session_state[f"spec_{current_segment_key}"] = generate_spectrogram_image(segment_y, sr)
                st.image(st.session_state[f"spec_{current_segment_key}"], caption="Spectrogram (dB)", use_container_width=True)

        # è·å–æ ‡ç­¾åˆ—è¡¨ï¼ˆè‹¥æœ‰æ›´æ–°åˆ™ç«‹å³ç”Ÿæ•ˆï¼‰
        species_list = st.session_state["dynamic_species_list"]
        with col_labels:
            st.markdown("### ç‰©ç§æ ‡ç­¾ï¼ˆå¯å¤šé€‰ï¼‰")
            current_key_prefix = current_segment_key

            # æ ‡ç­¾æœç´¢
            search_query = st.text_input("ğŸ” æœç´¢æ ‡ç­¾", value="", key=f"search_{current_key_prefix}")
            filtered_species = [label for label in species_list if search_query.lower() in label.lower()]

            # æ˜¾ç¤ºå·²é€‰æ ‡ç­¾
            st.info(f"å·²é€‰æ ‡ç­¾æ•°ï¼š{len(st.session_state.current_selected_labels)}")
            if st.session_state.current_selected_labels:
                st.success(f"å·²é€‰æ ‡ç­¾: {', '.join(st.session_state.current_selected_labels)}")
            else:
                st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾")

            # æ¸²æŸ“æ ‡ç­¾å¤é€‰æ¡†
            for label in filtered_species:
                key = f"label_{label}_{current_key_prefix}"
                is_selected = label in st.session_state.current_selected_labels
                if st.checkbox(label, key=key, value=is_selected):
                    st.session_state.current_selected_labels.add(label)
                else:
                    st.session_state.current_selected_labels.discard(label)

            # æ“ä½œæŒ‰é’®
            st.markdown("### ğŸ› ï¸ æ“ä½œ")
            col_save, col_skip = st.columns(2)
            with col_save:
                if st.button("ä¿å­˜æœ¬æ®µæ ‡æ³¨", key=f"save_{current_key_prefix}"):
                    selected_labels = list(st.session_state.current_selected_labels)
                    if not selected_labels:
                        st.warning("â—è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡ç­¾ï¼")
                    else:
                        try:
                            segment_filename = f"{os.path.splitext(audio_file.name)[0]}_seg{seg_idx}.wav"
                            segment_path = os.path.join(output_dir, segment_filename)
                            sf.write(segment_path, segment_y, sr)

                            entry = {
                                "filename": audio_file.name,
                                "segment_index": segment_filename,
                                "start_time": round(start_sec, 3),
                                "end_time": round(end_sec, 3),
                                "labels": ",".join(selected_labels)
                            }

                            st.session_state.annotations.append(entry)
                            df_combined = pd.concat([df_old, pd.DataFrame([entry])], ignore_index=True)
                            df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")

                            if seg_idx + 1 < total_segments:
                                st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                            else:
                                st.session_state.processed_files.add(audio_file.name)
                                st.session_state.current_index += 1

                            st.success("æ ‡æ³¨å·²ä¿å­˜ï¼")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ä¿å­˜å¤±è´¥ï¼š{str(e)}")

            with col_skip:
                if st.button("è·³è¿‡æœ¬æ®µ", key=f"skip_{current_key_prefix}"):
                    if seg_idx + 1 < total_segments:
                        st.session_state.segment_info[audio_file.name]["current_seg"] += 1
                    else:
                        st.session_state.processed_files.add(audio_file.name)
                        st.session_state.current_index += 1
                    st.rerun()

    else:
        st.success("ğŸ‰ æ‰€æœ‰ä¸Šä¼ çš„éŸ³é¢‘éƒ½å·²æ ‡æ³¨å®Œæˆï¼")

else:
    st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è‡³å°‘ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶")

# è‹¥æ ‡ç­¾éœ€è¦æ›´æ–°ï¼Œä»…åˆ·æ–°æ ‡ç­¾åŒºåŸŸï¼ˆå±€éƒ¨æ›´æ–°ï¼‰
if st.session_state.needs_label_update:
    st.session_state.needs_label_update = False
    st.experimental_rerun()  # è½»é‡çº§é‡è¿è¡Œï¼Œä»…æ›´æ–°å¿…è¦éƒ¨åˆ†
